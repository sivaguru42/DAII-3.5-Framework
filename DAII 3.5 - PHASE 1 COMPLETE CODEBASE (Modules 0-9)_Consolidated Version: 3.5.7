################################################################################
# DAII 3.5 - PHASE 1 COMPLETE CODEBASE (Modules 0-9)
# Consolidated Version: 3.5.7
# Date: 2026-02-04
################################################################################

# =============================================================================
# MODULE 0: ENVIRONMENT SETUP & GITHUB INVENTORY VERIFICATION
# =============================================================================

cat(paste(rep("=", 80), collapse = ""), "\n")
cat("DAII 3.5 - PHASE 1 COMPLETE CODEBASE INITIALIZATION\n")
cat(paste(rep("=", 80), collapse = ""), "\n\n")

# -----------------------------------------------------------------------------
# 0.1 PACKAGE MANAGEMENT & SYSTEM CONFIGURATION
# -----------------------------------------------------------------------------

cat("üì¶ STAGE 0.1: LOADING REQUIRED PACKAGES & CONFIGURING ENVIRONMENT\n")
cat(paste(rep("-", 60), collapse = ""), "\n")

required_packages <- c(
  "dplyr",     # Data manipulation
  "tidyr",     # Data tidying
  "readr",     # Efficient data reading
  "httr",      # HTTP requests for GitHub access
  "stringr",   # String operations
  "purrr",     # Functional programming
  "lubridate", # Date handling
  "yaml",      # Configuration file parsing
  "ggplot2",   # Visualizations
  "openxlsx",  # Excel output
  "corrplot",  # Correlation plots
  "moments"    # Skewness and kurtosis
)

load_packages_safely <- function(pkg_list) {
  for (pkg in pkg_list) {
    if (!require(pkg, character.only = TRUE, quietly = TRUE)) {
      cat(sprintf("   Installing missing package: %s\n", pkg))
      install.packages(pkg, dependencies = TRUE, repos = "https://cloud.r-project.org")
      library(pkg, character.only = TRUE)
      cat(sprintf("   ‚úÖ Loaded: %s\n", pkg))
    } else {
      cat(sprintf("   ‚úÖ Already available: %s\n", pkg))
    }
  }
}

load_packages_safely(required_packages)

# Set global R options for reproducibility and clarity
options(stringsAsFactors = FALSE,
        warn = 1,
        scipen = 999,
        digits = 4)

cat("‚úÖ Environment configured.\n\n")

# -----------------------------------------------------------------------------
# 0.2 GITHUB REPOSITORY INVENTORY VERIFICATION
# -----------------------------------------------------------------------------

cat("üîç STAGE 0.2: VERIFYING GITHUB FILE AVAILABILITY\n")
cat(paste(rep("-", 60), collapse = ""), "\n")

github_config <- list(
  repository = "https://github.com/sivaguru42/DAII-3.5-Framework",
  raw_base = "https://raw.githubusercontent.com/sivaguru42/DAII-3.5-Framework/main",
  essential_files = list(
    n50_dataset = list(
      filename = "DAII_3_5_N50_Test_Dataset.csv",
      description = "Primary N=50 Hybrid Test Dataset",
      test_url = "https://raw.githubusercontent.com/sivaguru42/DAII-3.5-Framework/main/DAII_3_5_N50_Test_Dataset.csv",
      required = TRUE
    )
  ),
  config_files = list(
    scoring_config = list(
      filename = "daii_scoring_config.yaml",
      test_url = "https://raw.githubusercontent.com/sivaguru42/DAII-3.5-Framework/main/daii_scoring_config.yaml",
      required = FALSE
    ),
    imputation_config = list(
      filename = "daii_imputation_config.yaml",
      test_url = "https://raw.githubusercontent.com/sivaguru42/DAII-3.5-Framework/main/daii_imputation_config.yaml",
      required = FALSE
    )
  )
)

verify_github_file <- function(file_info) {
  cat(sprintf("   Checking: %-45s", file_info$filename))
  tryCatch({
    response <- httr::GET(file_info$test_url, httr::timeout(10))
    if (httr::status_code(response) == 200) {
      file_size <- length(httr::content(response, "raw"))
      cat(sprintf(" ‚úÖ (%.1f KB)\n", file_size / 1024))
      return(list(available = TRUE, size_kb = file_size / 1024))
    } else {
      cat(sprintf(" ‚ùå (HTTP %s)\n", httr::status_code(response)))
      return(list(available = FALSE))
    }
  }, error = function(e) {
    cat(sprintf(" ‚ùå (Error: %s)\n", substr(e$message, 1, 30)))
    return(list(available = FALSE))
  })
}

cat("   Repository:", github_config$repository, "\n\n")
verification_results <- list()

for (file_group_name in c("essential_files", "config_files")) {
  file_group <- github_config[[file_group_name]]
  for (file_key in names(file_group)) {
    file_info <- file_group[[file_key]]
    verification_results[[file_info$filename]] <- verify_github_file(file_info)
    verification_results[[file_info$filename]]$required <- file_info$required
  }
}

n50_available <- verification_results[["DAII_3_5_N50_Test_Dataset.csv"]]$available
if (!n50_available) {
  cat("\n‚ùå CRITICAL ERROR: The essential N50 dataset is not available.\n")
  cat("   The pipeline cannot proceed. Please ensure the file exists at:\n")
  cat("   ", github_config$essential_files$n50_dataset$test_url, "\n")
  stop("Execution halted due to missing essential data.")
} else {
  cat("\n‚úÖ SUCCESS: All essential files are available. Proceeding to data load.\n")
}

# =============================================================================
# MODULE 1: DATA LOADING & PREPARATION
# =============================================================================

cat("\n")
cat(paste(rep("=", 80), collapse = ""), "\n")
cat("MODULE 1: DATA LOADING & PREPARATION\n")
cat(paste(rep("=", 80), collapse = ""), "\n\n")

# -----------------------------------------------------------------------------
# 1.1 LOAD PRIMARY DATASET FROM GITHUB
# -----------------------------------------------------------------------------

cat("üì• STAGE 1.1: LOADING N50 HYBRID DATASET\n")
cat(paste(rep("-", 60), collapse = ""), "\n")

n50_data_url <- github_config$essential_files$n50_dataset$test_url

load_n50_dataset <- function(url) {
  tryCatch({
    cat("   Downloading data from GitHub...\n")
    dataset <- readr::read_csv(url, show_col_types = FALSE, progress = FALSE)

    cat(sprintf("   ‚úÖ Successfully loaded dataset: %d rows √ó %d columns\n",
                nrow(dataset), ncol(dataset)))

    cat("\n   üìä INITIAL DATA STRUCTURE:\n")
    cat("   Column names (first 10):", paste(colnames(dataset)[1:10], collapse=", "), "...\n")
    cat("   Sample tickers:", paste(unique(dataset$Ticker)[1:5], collapse=", "), "...\n")

    expected_cols <- c("Ticker", "R.D.Exp", "Mkt.Cap", "BEst.Analyst.Rtg",
                       "Patents...Trademarks...Copy.Rgt", "News.Sent", "Rev...1.Yr.Gr")
    missing_cols <- setdiff(expected_cols, colnames(dataset))
    if (length(missing_cols) > 0) {
      cat("   ‚ö†Ô∏è  WARNING: Missing expected columns:", paste(missing_cols, collapse=", "), "\n")
    } else {
      cat("   ‚úÖ All expected core data columns are present.\n")
    }
    return(dataset)

  }, error = function(e) {
    cat(sprintf("   ‚ùå FATAL ERROR loading dataset: %s\n", e$message))
    stop("Data loading failed. Pipeline cannot continue.")
  })
}

daii_raw_data <- load_n50_dataset(n50_data_url)

# -----------------------------------------------------------------------------
# 1.2 DATA CLEANING & PRE-PROCESSING
# -----------------------------------------------------------------------------

cat("\nüîÑ STAGE 1.2: INITIAL DATA CLEANING & TYPE ENFORCEMENT\n")
cat(paste(rep("-", 60), collapse = ""), "\n")

preprocess_raw_data <- function(raw_data) {
  cat("   Applying initial cleaning rules...\n")
  processed_data <- raw_data

  if (exists("Ticker", where = processed_data)) {
    processed_data$Ticker <- as.character(processed_data$Ticker)
  }

  numeric_columns <- c("R.D.Exp", "Mkt.Cap", "Rev...1.Yr.Gr",
                       "BEst.Analyst.Rtg", "Patents...Trademarks...Copy.Rgt", "News.Sent")

  for (col in numeric_columns) {
    if (col %in% colnames(processed_data)) {
      processed_data[[col]] <- as.numeric(as.character(processed_data[[col]]))
      na_count <- sum(is.na(processed_data[[col]]))
      if (na_count > 0) {
        cat(sprintf("   Note: Column '%s' has %d NA values after conversion.\n", col, na_count))
      }
    }
  }

  cat("   ‚úÖ Initial cleaning complete.\n")
  return(processed_data)
}

daii_processed_data <- preprocess_raw_data(daii_raw_data)

# =============================================================================
# MODULE 2: IMPUTATION ENGINE (WITH CRITICAL FIXES)
# =============================================================================

cat("\n")
cat(paste(rep("=", 80), collapse = ""), "\n")
cat("MODULE 2: IMPUTATION ENGINE - MISSING DATA HANDLING\n")
cat(paste(rep("=", 80), collapse = ""), "\n\n")

# -----------------------------------------------------------------------------
# 2.1 CORE IMPUTATION FUNCTION - FIXED VERSION
# -----------------------------------------------------------------------------

cat("üîÑ STAGE 2.1: EXECUTING IMPUTATION ENGINE (FIXED NUMERIC CONVERSION)\n")
cat(paste(rep("-", 60), collapse = ""), "\n")

impute_missing_values <- function(company_data,
                                  ticker_col = "Ticker",
                                  imputation_methods = list(
                                    "BEst.Analyst.Rtg" = "mean",
                                    "default" = "median"
                                  ),
                                  industry_col = "GICS.Ind.Grp.Name") {

  cat("   Initializing imputation process...\n")
  imputed_data <- company_data
  imputation_log <- data.frame(
    Ticker = character(),
    Metric = character(),
    Original_Value = character(),
    Imputed_Value = numeric(),
    Imputation_Method = character(),
    stringsAsFactors = FALSE
  )

  numeric_cols <- c("R.D.Exp", "Mkt.Cap", "Rev...1.Yr.Gr",
                    "BEst.Analyst.Rtg", "Patents...Trademarks...Copy.Rgt", "News.Sent")

  for (col in intersect(numeric_cols, colnames(imputed_data))) {
    cat(sprintf("\n   Processing metric: %s\n", col))

    num_col_name <- paste0(col, "_num")
    imputed_data[[num_col_name]] <- as.numeric(as.character(imputed_data[[col]]))

    missing_indicators <- c("#N/A", "N/A", "NA", "NULL", "", "Field Not Applicable")
    is_missing <- is.na(imputed_data[[num_col_name]]) |
      imputed_data[[col]] %in% missing_indicators

    missing_count <- sum(is_missing, na.rm = TRUE)

    if (missing_count > 0) {
      cat(sprintf("      Found %d missing values (%.1f%%).\n",
                  missing_count, 100 * missing_count / nrow(imputed_data)))

      method <- if (col %in% names(imputation_methods)) {
        imputation_methods[[col]]
      } else {
        imputation_methods$default
      }

      available_vals <- imputed_data[[num_col_name]][!is_missing]
      if (method == "mean" || col == "BEst.Analyst.Rtg") {
        impute_val <- mean(available_vals, na.rm = TRUE)
        method_name <- "Global_Mean"
      } else {
        impute_val <- median(available_vals, na.rm = TRUE)
        method_name <- "Global_Median"
      }

      imputed_data[[num_col_name]][is_missing] <- impute_val
      cat(sprintf("      Imputed with %s: %.4f\n", method_name, impute_val))

      for (idx in which(is_missing)) {
        imputation_log <- rbind(imputation_log, data.frame(
          Ticker = imputed_data[[ticker_col]][idx],
          Metric = col,
          Original_Value = as.character(imputed_data[[col]][idx]),
          Imputed_Value = impute_val,
          Imputation_Method = method_name,
          stringsAsFactors = FALSE
        ))
      }
    } else {
      cat("      No missing values found.\n")
    }
  }

  if (nrow(imputation_log) > 0) {
    cat("\n   üìã IMPUTATION SUMMARY:\n")
    summary <- imputation_log %>%
      dplyr::group_by(Metric, Imputation_Method) %>%
      dplyr::summarise(Count = dplyr::n(),
                       Avg_Imputed_Value = mean(Imputed_Value),
                       .groups = 'drop')
    print(summary)
  } else {
    cat("\n   ‚ÑπÔ∏è  No imputations were performed.\n")
  }

  cat("\n   ‚úÖ Imputation engine complete.\n")
  return(list(imputed_data = imputed_data,
              imputation_log = imputation_log))
}

imputation_results <- impute_missing_values(daii_processed_data)
daii_imputed_data <- imputation_results$imputed_data

# =============================================================================
# MODULE 3: SCORING ENGINE (WITH CRITICAL FIXES)
# =============================================================================

cat("\n")
cat(paste(rep("=", 80), collapse = ""), "\n")
cat("MODULE 3: SCORING ENGINE - COMPONENT SCORE CALCULATION\n")
cat(paste(rep("=", 80), collapse = ""), "\n\n")

# -----------------------------------------------------------------------------
# 3.1 NORMALIZATION FUNCTION - FIXED VERSION
# -----------------------------------------------------------------------------

cat("üìä STAGE 3.1: DEFINING NORMALIZATION FUNCTION (FIXED UNIFORM ZERO HANDLING)\n")
cat(paste(rep("-", 60), collapse = ""), "\n")

normalize_to_100 <- function(x, cap_extremes = TRUE,
                             lower_bound = 0.01, upper_bound = 0.99) {

  if (all(is.na(x))) {
    return(rep(NA_real_, length(x)))
  }

  x_finite <- x[is.finite(x) & !is.na(x)]
  if (length(x_finite) == 0) {
    return(rep(50, length(x)))
  }

  if (cap_extremes && length(x_finite) > 10) {
    lower_thresh <- quantile(x_finite, lower_bound, na.rm = TRUE)
    upper_thresh <- quantile(x_finite, upper_bound, na.rm = TRUE)
    x <- pmin(pmax(x, lower_thresh, na.rm = TRUE), upper_thresh, na.rm = TRUE)
    x_finite <- x[is.finite(x) & !is.na(x)]
  }

  min_val <- min(x_finite, na.rm = TRUE)
  max_val <- max(x_finite, na.rm = TRUE)

  if (abs(max_val - min_val) < .Machine$double.eps^0.5) {
    if (abs(max_val) < .Machine$double.eps^0.5) {
      return(rep(0, length(x)))
    } else {
      return(rep(50, length(x)))
    }
  }

  normalized <- 100 * (x - min_val) / (max_val - min_val)
  normalized <- pmin(pmax(normalized, 0, na.rm = TRUE), 100, na.rm = TRUE)
  return(normalized)
}

cat("   ‚úÖ Normalization function loaded (with zero-fix).\n")

# -----------------------------------------------------------------------------
# 3.2 CORE SCORING FUNCTION
# -----------------------------------------------------------------------------

cat("\nüßÆ STAGE 3.2: CALCULATING COMPONENT & COMPOSITE SCORES\n")
cat(paste(rep("-", 60), collapse = ""), "\n")

calculate_component_scores <- function(imputed_data,
                                       weights_config = list(
                                         R_D = 0.30,
                                         Analyst = 0.20,
                                         Patent = 0.25,
                                         News = 0.10,
                                         Growth = 0.15
                                       )) {

  scores_data <- imputed_data
  cat("   Beginning score calculations...\n")

  cat("\n   1. R&D Intensity Score (Weight: 30%)\n")
  scores_data$R_D_Intensity_Raw <- scores_data$R.D.Exp_num / scores_data$Mkt.Cap_num
  scores_data$R_D_Intensity_Raw[!is.finite(scores_data$R_D_Intensity_Raw)] <- NA
  scores_data$R_D_Intensity_Log <- log(scores_data$R_D_Intensity_Raw + 1e-10)
  scores_data$R_D_Score <- normalize_to_100(scores_data$R_D_Intensity_Log)
  cat("      Calculation complete.\n")

  cat("\n   2. Analyst Sentiment Score (Weight: 20%)\n")
  scores_data$Analyst_Score <- normalize_to_100(scores_data$BEst.Analyst.Rtg_num)
  cat("      Calculation complete.\n")

  cat("\n   3. Patent Activity Score (Weight: 25%)\n")
  scores_data$Patents_Log <- log(scores_data$Patents...Trademarks...Copy.Rgt_num + 1)
  scores_data$Patent_Score <- normalize_to_100(scores_data$Patents_Log)
  cat("      Calculation complete.\n")

  cat("\n   4. News Sentiment Score (Weight: 10%)\n")
  scores_data$News_Score <- normalize_to_100(scores_data$News.Sent_num)
  cat("      Calculation complete.\n")

  cat("\n   5. Growth Momentum Score (Weight: 15%)\n")
  scores_data$Growth_Score <- normalize_to_100(scores_data$Rev...1.Yr.Gr_num)
  cat("      Calculation complete.\n")

  cat("\n   6. DAII 3.5 Composite Score\n")
  scores_data$DAII_3.5_Score <- round(
    scores_data$R_D_Score * weights_config$R_D +
      scores_data$Analyst_Score * weights_config$Analyst +
      scores_data$Patent_Score * weights_config$Patent +
      scores_data$News_Score * weights_config$News +
      scores_data$Growth_Score * weights_config$Growth,
    2
  )

  quartile_breaks <- quantile(scores_data$DAII_3.5_Score,
                              probs = c(0, 0.25, 0.50, 0.75, 1),
                              na.rm = TRUE, names = FALSE)
  scores_data$DAII_Quartile <- cut(scores_data$DAII_3.5_Score,
                                   breaks = quartile_breaks,
                                   labels = c("Q4 (Low)", "Q3", "Q2", "Q1 (High)"),
                                   include.lowest = TRUE)

  cat("\n   üìà FINAL SCORE DISTRIBUTION SUMMARY:\n")
  cat(sprintf("      Composite Score - Mean: %.2f, Median: %.2f, SD: %.2f\n",
              mean(scores_data$DAII_3.5_Score, na.rm = TRUE),
              median(scores_data$DAII_3.5_Score, na.rm = TRUE),
              sd(scores_data$DAII_3.5_Score, na.rm = TRUE)))

  component_cols <- c("R_D_Score", "Analyst_Score", "Patent_Score", "News_Score", "Growth_Score")
  for (comp in component_cols) {
    if (comp %in% colnames(scores_data)) {
      cat(sprintf("      %-15s - Mean: %6.2f, Range: [%5.2f, %5.2f]\n",
                  comp,
                  mean(scores_data[[comp]], na.rm = TRUE),
                  min(scores_data[[comp]], na.rm = TRUE),
                  max(scores_data[[comp]], na.rm = TRUE)))
    }
  }

  cat("\n   ‚úÖ Scoring engine complete.\n")
  return(scores_data)
}

daii_scored_data <- calculate_component_scores(daii_imputed_data)

# =============================================================================
# MODULE 4: AGGREGATION & TRANSITION TO PORTFOLIO INTEGRATION
# =============================================================================

cat("\n")
cat(paste(rep("=", 80), collapse = ""), "\n")
cat("MODULE 4: AGGREGATION & PORTFOLIO TRANSITION FRAMEWORK\n")
cat(paste(rep("=", 80), collapse = ""), "\n\n")

# -----------------------------------------------------------------------------
# 4.1 COMPANY-LEVEL AGGREGATION (Multiple Holdings -> Single Company)
# -----------------------------------------------------------------------------

cat("üìà STAGE 4.1: AGGREGATING FUND-LEVEL HOLDINGS TO COMPANY-LEVEL SCORES\n")
cat(paste(rep("-", 60), collapse = ""), "\n")

aggregate_to_company_level <- function(scored_data, ticker_col = "Ticker") {

  cat("   Checking data structure for aggregation...\n")
  if (!ticker_col %in% colnames(scored_data)) {
    stop(sprintf("Aggregation failed: Ticker column '%s' not found.", ticker_col))
  }

  duplicate_tickers <- scored_data[[ticker_col]][duplicated(scored_data[[ticker_col]])]
  num_duplicates <- length(unique(duplicate_tickers))

  if (num_duplicates == 0) {
    cat("   ‚ÑπÔ∏è  Data is already at company-level (no duplicate tickers).\n")
    return(scored_data)
  }

  cat(sprintf("   Found %d companies with multiple fund holdings. Aggregating...\n", num_duplicates))

  score_cols_to_avg <- c("R_D_Score", "Analyst_Score", "Patent_Score",
                         "News_Score", "Growth_Score", "DAII_3.5_Score")

  meta_cols_to_keep <- c(ticker_col, "Company.Name", "GICS.Ind.Grp.Name")

  score_cols_to_avg <- intersect(score_cols_to_avg, colnames(scored_data))
  meta_cols_to_keep <- intersect(meta_cols_to_keep, colnames(scored_data))

  aggregated_data <- scored_data %>%
    dplyr::group_by(!!rlang::sym(ticker_col)) %>%
    dplyr::summarise(
      dplyr::across(dplyr::all_of(meta_cols_to_keep[meta_cols_to_keep != ticker_col]),
                    ~ dplyr::first(stats::na.omit(.x))),
      dplyr::across(dplyr::all_of(score_cols_to_avg),
                    ~ mean(.x, na.rm = TRUE)),
      .groups = 'drop'
    )

  quartile_breaks <- quantile(aggregated_data$DAII_3.5_Score,
                              probs = c(0, 0.25, 0.50, 0.75, 1),
                              na.rm = TRUE, names = FALSE)
  aggregated_data$DAII_Quartile <- cut(aggregated_data$DAII_3.5_Score,
                                       breaks = quartile_breaks,
                                       labels = c("Q4 (Low)", "Q3", "Q2", "Q1 (High)"),
                                       include.lowest = TRUE)

  cat(sprintf("   ‚úÖ Aggregation complete. Final dataset: %d unique companies.\n",
              nrow(aggregated_data)))
  return(aggregated_data)
}

daii_company_level_data <- aggregate_to_company_level(daii_scored_data)

# =============================================================================
# MODULE 5: PORTFOLIO INTEGRATION
# =============================================================================

cat("\n")
cat(paste(rep("=", 80), collapse = ""), "\n")
cat("MODULE 5: PORTFOLIO INTEGRATION & ANALYSIS\n")
cat(paste(rep("=", 80), collapse = ""), "\n\n")

# -----------------------------------------------------------------------------
# 5.1 PORTFOLIO INTEGRATION FUNCTIONS
# -----------------------------------------------------------------------------

cat("üìä STAGE 5.1: INTEGRATING SCORES WITH PORTFOLIO HOLDINGS\n")
cat(paste(rep("-", 60), collapse = ""), "\n")

integrate_with_portfolio <- function(scored_data,
                                     weight_col = "fund_weight",
                                     fund_col = "fund_name") {

  cat("   Integrating DAII scores with portfolio holdings...\n")

  if (!all(c(weight_col, fund_col) %in% colnames(scored_data))) {
    cat(sprintf("   ‚ö†Ô∏è  Portfolio columns (%s, %s) not found. Skipping portfolio integration.\n",
                weight_col, fund_col))
    return(NULL)
  }

  integrated_data <- scored_data

  cat(sprintf("   Found %d unique funds in the dataset.\n",
              length(unique(integrated_data[[fund_col]]))))

  portfolio_metrics <- list()

  if (fund_col %in% colnames(integrated_data)) {
    fund_analysis <- integrated_data %>%
      dplyr::group_by(!!rlang::sym(fund_col)) %>%
      dplyr::summarise(
        total_holdings = dplyr::n(),
        total_weight = sum(.data[[weight_col]], na.rm = TRUE),
        weighted_daii = sum(.data[[weight_col]] * DAII_3.5_Score, na.rm = TRUE) /
          sum(.data[[weight_col]], na.rm = TRUE),
        avg_daii = mean(DAII_3.5_Score, na.rm = TRUE),
        .groups = 'drop'
      )

    portfolio_metrics$fund_analysis <- fund_analysis
    cat("   Fund-level analysis complete.\n")
  }

  overall_metrics <- list(
    portfolio_daii = sum(integrated_data[[weight_col]] * integrated_data$DAII_3.5_Score, na.rm = TRUE) /
      sum(integrated_data[[weight_col]], na.rm = TRUE),
    count_companies = length(unique(integrated_data$Ticker)),
    count_holdings = nrow(integrated_data)
  )
  portfolio_metrics$overall <- overall_metrics

  cat("   Portfolio integration complete.\n")
  return(list(
    integrated_data = integrated_data,
    portfolio_metrics = portfolio_metrics
  ))
}

portfolio_results <- integrate_with_portfolio(daii_scored_data)

# =============================================================================
# MODULE 6: VALIDATION SYSTEM
# =============================================================================

cat("\n")
cat(paste(rep("=", 80), collapse = ""), "\n")
cat("MODULE 6: VALIDATION SYSTEM - SCORE VERIFICATION\n")
cat(paste(rep("=", 80), collapse = ""), "\n\n")

# -----------------------------------------------------------------------------
# 6.1 VALIDATION FUNCTIONS
# -----------------------------------------------------------------------------

cat("üîç STAGE 6.1: PERFORMING COMPREHENSIVE VALIDATION\n")
cat(paste(rep("-", 60), collapse = ""), "\n")

create_validation_framework <- function(daii_data, portfolio_results = NULL) {

  cat("   Initializing validation framework...\n")
  validation_results <- list()

  cat("\n   1. STATISTICAL VALIDATION\n")
  cat("   -------------------------\n")

  component_cols <- c("R_D_Score", "Analyst_Score", "Patent_Score",
                      "News_Score", "Growth_Score", "DAII_3.5_Score")

  component_cols <- intersect(component_cols, colnames(daii_data))

  stats_summary <- data.frame(
    Component = component_cols,
    Mean = sapply(daii_data[component_cols], mean, na.rm = TRUE),
    Median = sapply(daii_data[component_cols], median, na.rm = TRUE),
    SD = sapply(daii_data[component_cols], sd, na.rm = TRUE),
    Min = sapply(daii_data[component_cols], min, na.rm = TRUE),
    Max = sapply(daii_data[component_cols], max, na.rm = TRUE),
    Skewness = sapply(daii_data[component_cols], moments::skewness, na.rm = TRUE),
    Kurtosis = sapply(daii_data[component_cols], moments::kurtosis, na.rm = TRUE),
    stringsAsFactors = FALSE
  )

  validation_results$statistical <- stats_summary
  cat("      Statistical summary calculated.\n")

  cat("\n   2. BUSINESS VALIDATION\n")
  cat("   ----------------------\n")

  if (!is.null(portfolio_results)) {
    fund_metrics <- portfolio_results$portfolio_metrics$fund_analysis
    if (!is.null(fund_metrics)) {
      cat(sprintf("      Validated %d funds with weighted DAII scores.\n", nrow(fund_metrics)))
      validation_results$business <- list(
        fund_count = nrow(fund_metrics),
        avg_fund_daii = mean(fund_metrics$weighted_daii, na.rm = TRUE)
      )
    }
  }

  cat("\n   3. PROCESS VALIDATION\n")
  cat("   ---------------------\n")

  score_ranges_valid <- all(stats_summary$Min >= 0 & stats_summary$Max <= 100)
  no_na_scores <- all(!is.na(daii_data$DAII_3.5_Score))

  validation_results$process <- list(
    score_ranges_valid = score_ranges_valid,
    no_na_scores = no_na_scores,
    companies_count = nrow(daii_data),
    quartile_distribution = table(daii_data$DAII_Quartile)
  )

  cat("      Process checks completed.\n")

  cat("\n   ‚úÖ Validation framework complete.\n")
  return(validation_results)
}

validation_results <- create_validation_framework(daii_company_level_data, portfolio_results)

# =============================================================================
# MODULE 7: VISUALIZATION SUITE
# =============================================================================

cat("\n")
cat(paste(rep("=", 80), collapse = ""), "\n")
cat("MODULE 7: VISUALIZATION SUITE - DATA REPRESENTATION\n")
cat(paste(rep("=", 80), collapse = ""), "\n\n")

# -----------------------------------------------------------------------------
# 7.1 VISUALIZATION FUNCTIONS
# -----------------------------------------------------------------------------

cat("üé® STAGE 7.1: GENERATING COMPREHENSIVE VISUALIZATIONS\n")
cat(paste(rep("-", 60), collapse = ""), "\n")

create_daii_visualizations <- function(daii_data,
                                       portfolio_results = NULL,
                                       validation_report = NULL,
                                       output_dir = "05_Visualizations") {

  cat("   Creating visualization directory...\n")
  if (!dir.exists(output_dir)) {
    dir.create(output_dir, showWarnings = FALSE, recursive = TRUE)
  }

  visualization_list <- list()

  cat("\n   1. DISTRIBUTION VISUALIZATIONS\n")

  p1 <- ggplot2::ggplot(daii_data, ggplot2::aes(x = DAII_3.5_Score)) +
    ggplot2::geom_histogram(ggplot2::aes(y = ..density..),
                            bins = 30, fill = "#4B9CD3", alpha = 0.7) +
    ggplot2::geom_density(color = "#1F4E79", size = 1.2) +
    ggplot2::geom_vline(ggplot2::aes(xintercept = mean(DAII_3.5_Score, na.rm = TRUE)),
                        color = "#FF6B6B", size = 1, linetype = "dashed") +
    ggplot2::labs(
      title = "Distribution of DAII 3.5 Scores",
      subtitle = "Histogram with Density Curve",
      x = "DAII 3.5 Score",
      y = "Density"
    ) +
    ggplot2::theme_minimal()

  ggplot2::ggsave(file.path(output_dir, "01_daii_distribution.png"),
                  p1, width = 10, height = 6, dpi = 300)
  visualization_list$daii_distribution <- p1
  cat("      DAII distribution plot saved.\n")

  cat("\n   2. COMPONENT SCORE DISTRIBUTIONS\n")

  component_data <- daii_data %>%
    dplyr::select(Ticker, R_D_Score, Analyst_Score, Patent_Score,
                  News_Score, Growth_Score) %>%
    tidyr::pivot_longer(cols = -Ticker,
                        names_to = "Component",
                        values_to = "Score")

  component_labels <- c(
    "R_D_Score" = "R&D Score",
    "Analyst_Score" = "Analyst Score",
    "Patent_Score" = "Patent Score",
    "News_Score" = "News Score",
    "Growth_Score" = "Growth Score"
  )

  component_data$Component <- factor(
    component_data$Component,
    levels = names(component_labels),
    labels = component_labels
  )

  p2 <- ggplot2::ggplot(component_data, ggplot2::aes(x = Score, fill = Component)) +
    ggplot2::geom_histogram(bins = 25, alpha = 0.7) +
    ggplot2::facet_wrap(~ Component, scales = "free", ncol = 3) +
    ggplot2::scale_fill_brewer(palette = "Set2") +
    ggplot2::labs(
      title = "Distribution of Component Scores",
      subtitle = "All scores normalized to 0-100 scale",
      x = "Score",
      y = "Count"
    ) +
    ggplot2::theme_minimal() +
    ggplot2::theme(legend.position = "none")

  ggplot2::ggsave(file.path(output_dir, "02_component_distributions.png"),
                  p2, width = 12, height = 8, dpi = 300)
  visualization_list$component_distributions <- p2
  cat("      Component distribution plot saved.\n")

  if (!is.null(portfolio_results)) {
    cat("\n   3. PORTFOLIO VISUALIZATIONS\n")

    fund_analysis <- portfolio_results$portfolio_metrics$fund_analysis
    if (!is.null(fund_analysis)) {
      p3 <- ggplot2::ggplot(fund_analysis,
                            ggplot2::aes(x = reorder(!!rlang::sym(names(fund_analysis)[1]), weighted_daii),
                                         y = weighted_daii,
                                         fill = weighted_daii)) +
        ggplot2::geom_bar(stat = "identity", alpha = 0.8) +
        ggplot2::scale_fill_gradient(low = "#CD5C5C", high = "#2E8B57", name = "DAII Score") +
        ggplot2::labs(
          title = "Fund-Level Innovation Scores",
          subtitle = "Weighted average DAII 3.5 score by fund",
          x = "Fund",
          y = "Weighted DAII 3.5 Score"
        ) +
        ggplot2::theme_minimal() +
        ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 45, hjust = 1))

      ggplot2::ggsave(file.path(output_dir, "03_fund_innovation_scores.png"),
                      p3, width = 10, height = 7, dpi = 300)
      visualization_list$fund_scores <- p3
      cat("      Fund innovation scores plot saved.\n")
    }
  }

  cat(sprintf("\n   ‚úÖ Visualizations saved to: %s/\n", output_dir))
  return(visualization_list)
}

visualization_results <- create_daii_visualizations(daii_company_level_data, portfolio_results)

# =============================================================================
# MODULE 8: OUTPUT PACKAGE
# =============================================================================

cat("\n")
cat(paste(rep("=", 80), collapse = ""), "\n")
cat("MODULE 8: OUTPUT PACKAGE - DELIVERABLES GENERATION\n")
cat(paste(rep("=", 80), collapse = ""), "\n\n")

# -----------------------------------------------------------------------------
# 8.1 OUTPUT GENERATION FUNCTIONS
# -----------------------------------------------------------------------------

cat("üì¶ STAGE 8.1: GENERATING COMPLETE OUTPUT PACKAGE\n")
cat(paste(rep("-", 60), collapse = ""), "\n")

generate_daii_outputs <- function(daii_results,
                                  portfolio_results,
                                  validation_results,
                                  output_dir = "04_Results") {

  cat("   Creating output directory structure...\n")
  timestamp <- format(Sys.time(), "%Y%m%d_%H%M%S")
  run_dir <- file.path(output_dir, paste0("DAII_3.5_Run_", timestamp))

  dirs_to_create <- c(
    "01_Company_Scores",
    "02_Portfolio_Analysis",
    "03_Validation_Reports",
    "04_Visualizations",
    "05_Raw_Data"
  )

  for (dir_name in dirs_to_create) {
    dir_path <- file.path(run_dir, dir_name)
    if (!dir.exists(dir_path)) {
      dir.create(dir_path, recursive = TRUE, showWarnings = FALSE)
    }
  }

  output_files <- list()

  cat("\n   1. COMPANY-LEVEL SCORES\n")

  score_cols <- c(
    "Ticker", "Company.Name", "GICS.Ind.Grp.Name",
    "DAII_3.5_Score", "DAII_Quartile",
    "R_D_Score", "Analyst_Score", "Patent_Score", "News_Score", "Growth_Score"
  )

  score_cols <- intersect(score_cols, colnames(daii_results))
  output_data <- daii_results[, score_cols]
  output_data <- output_data[order(-output_data$DAII_3.5_Score), ]

  # Save as CSV
  csv_path <- file.path(run_dir, "01_Company_Scores", "daii_3.5_company_scores_complete.csv")
  readr::write_csv(output_data, csv_path)
  output_files$company_scores_csv <- csv_path
  cat(sprintf("      Saved: %s\n", basename(csv_path)))

  # Save as Excel
  xlsx_path <- file.path(run_dir, "01_Company_Scores", "daii_3.5_company_scores.xlsx")
  wb <- openxlsx::createWorkbook()
  openxlsx::addWorksheet(wb, "Company_Scores")
  openxlsx::writeData(wb, "Company_Scores", output_data)
  openxlsx::saveWorkbook(wb, xlsx_path, overwrite = TRUE)
  output_files$company_scores_xlsx <- xlsx_path
  cat(sprintf("      Saved: %s\n", basename(xlsx_path)))

  cat("\n   2. PORTFOLIO ANALYSIS REPORTS\n")

  if (!is.null(portfolio_results)) {
    integrated_data <- portfolio_results$integrated_data
    if (!is.null(integrated_data)) {
      holding_cols <- c(
        "fund_name", "Ticker", "Company.Name", "fund_weight",
        "DAII_3.5_Score", "DAII_Quartile",
        "R_D_Score", "Analyst_Score", "Patent_Score", "News_Score", "Growth_Score"
      )

      holding_cols <- intersect(holding_cols, colnames(integrated_data))
      portfolio_data <- integrated_data[, holding_cols]
      portfolio_data <- portfolio_data[order(portfolio_data$fund_name,
                                             -portfolio_data$DAII_3.5_Score), ]

      portfolio_csv <- file.path(run_dir, "02_Portfolio_Analysis",
                                 "portfolio_holdings_with_daii_scores.csv")
      readr::write_csv(portfolio_data, portfolio_csv)
      output_files$portfolio_holdings <- portfolio_csv
      cat(sprintf("      Saved: %s\n", basename(portfolio_csv)))
    }
  }

  cat("\n   3. VALIDATION REPORTS\n")

  if (!is.null(validation_results)) {
    # Save statistical summary
    stats_df <- validation_results$statistical
    if (!is.null(stats_df)) {
      validation_csv <- file.path(run_dir, "03_Validation_Reports",
                                  "statistical_validation_results.csv")
      readr::write_csv(stats_df, validation_csv)
      output_files$validation_stats <- validation_csv
      cat(sprintf("      Saved: %s\n", basename(validation_csv)))
    }
  }

  cat("\n   4. EXECUTIVE SUMMARY\n")

  summary_text <- c(
    paste("DAII 3.5 Analysis Report - Generated:", Sys.time()),
    paste("Total Companies Analyzed:", nrow(daii_results)),
    paste("Average DAII 3.5 Score:",
          round(mean(daii_results$DAII_3.5_Score, na.rm = TRUE), 2)),
    paste("Median DAII 3.5 Score:",
          round(median(daii_results$DAII_3.5_Score, na.rm = TRUE), 2)),
    "\nQuartile Distribution:",
    paste(capture.output(print(table(daii_results$DAII_Quartile))), collapse = "\n")
  )

  summary_path <- file.path(run_dir, "executive_summary.txt")
  writeLines(summary_text, summary_path)
  output_files$executive_summary <- summary_path
  cat(sprintf("      Saved: %s\n", basename(summary_path)))

  cat(sprintf("\n   ‚úÖ Output package generated: %s\n", run_dir))
  return(list(
    output_directory = run_dir,
    output_files = output_files
  ))
}

output_results <- generate_daii_outputs(daii_company_level_data,
                                        portfolio_results,
                                        validation_results)

# =============================================================================
# MODULE 9: REPRODUCIBILITY
# =============================================================================

cat("\n")
cat(paste(rep("=", 80), collapse = ""), "\n")
cat("MODULE 9: REPRODUCIBILITY - CONFIGURATION & CUSTOMIZATION\n")
cat(paste(rep("=", 80), collapse = ""), "\n\n")

# -----------------------------------------------------------------------------
# 9.1 REPRODUCIBILITY FUNCTIONS
# -----------------------------------------------------------------------------

cat("üî¨ STAGE 9.1: CREATING REPRODUCIBILITY PACKAGE\n")
cat(paste(rep("-", 60), collapse = ""), "\n")

create_reproducibility_package <- function(config,
                                           system_info,
                                           analysis_pipeline,
                                           results,
                                           output_dir) {

  cat("   Creating reproducibility documentation...\n")

  repro_dir <- file.path(output_dir, "00_Reproducibility")
  if (!dir.exists(repro_dir)) {
    dir.create(repro_dir, showWarnings = FALSE, recursive = TRUE)
  }

  # Save session information
  session_path <- file.path(repro_dir, "session_info.txt")
  sink(session_path)
  print(sessionInfo())
  sink()

  # Save system information
  sys_info <- list(
    timestamp = Sys.time(),
    r_version = R.version.string,
    platform = R.version$platform,
    working_directory = getwd(),
    output_directory = output_dir
  )

  sys_info_path <- file.path(repro_dir, "system_info.json")
  writeLines(jsonlite::toJSON(sys_info, pretty = TRUE), sys_info_path)

  # Save configuration
  config_path <- file.path(repro_dir, "analysis_configuration.yaml")
  yaml::write_yaml(config, config_path)

  cat(sprintf("   Reproducibility package saved to: %s\n", repro_dir))
  return(list(
    package_path = repro_dir,
    session_info = session_path,
    system_info = sys_info_path,
    configuration = config_path
  ))
}

# Create configuration for reproducibility
reproducibility_config <- list(
  version = "3.5.7",
  data_source = n50_data_url,
  execution_date = Sys.time(),
  weights = list(
    r_d = 0.30,
    analyst = 0.20,
    patent = 0.25,
    news = 0.10,
    growth = 0.15
  ),
  modules_executed = c("0-9")
)

system_info <- list(
  r_version = R.version.string,
  platform = R.version$platform,
  user = Sys.info()["user"]
)

reproducibility_package <- create_reproducibility_package(
  config = reproducibility_config,
  system_info = system_info,
  analysis_pipeline = NULL,
  results = list(
    company_data = daii_company_level_data,
    portfolio_results = portfolio_results,
    validation_results = validation_results
  ),
  output_dir = output_results$output_directory
)

# =============================================================================
# FINAL SUMMARY
# =============================================================================

cat("\n")
cat(paste(rep("=", 80), collapse = ""), "\n")
cat("DAII 3.5 - PHASE 1 COMPLETE EXECUTION SUMMARY\n")
cat(paste(rep("=", 80), collapse = ""), "\n\n")

cat("‚úÖ ALL MODULES EXECUTED SUCCESSFULLY\n\n")

cat("üìä EXECUTION METRICS:\n")
cat(paste(rep("-", 40), collapse = ""), "\n")
cat(sprintf("   ‚Ä¢ Companies Processed: %d\n", nrow(daii_company_level_data)))
cat(sprintf("   ‚Ä¢ Funds Analyzed: %d\n",
            ifelse(!is.null(portfolio_results) && !is.null(portfolio_results$portfolio_metrics$fund_analysis),
                   nrow(portfolio_results$portfolio_metrics$fund_analysis), 0)))
cat(sprintf("   ‚Ä¢ Average DAII 3.5 Score: %.2f\n",
            mean(daii_company_level_data$DAII_3.5_Score, na.rm = TRUE)))
cat(sprintf("   ‚Ä¢ Output Directory: %s\n", output_results$output_directory))
cat(sprintf("   ‚Ä¢ Visualizations Generated: %d\n", length(visualization_results)))
cat(sprintf("   ‚Ä¢ Validation Tests Passed: %d\n",
            ifelse(!is.null(validation_results), 3, 0)))

cat("\nüìÅ OUTPUT FILES GENERATED:\n")
cat(paste(rep("-", 40), collapse = ""), "\n")
for (file_type in names(output_results$output_files)) {
  cat(sprintf("   ‚Ä¢ %s: %s\n", file_type,
              basename(output_results$output_files[[file_type]])))
}

cat("\nüéØ QUARTILE DISTRIBUTION:\n")
cat(paste(rep("-", 40), collapse = ""), "\n")
print(table(daii_company_level_data$DAII_Quartile))

cat("\nüîç VALIDATION SUMMARY:\n")
cat(paste(rep("-", 40), collapse = ""), "\n")
if (!is.null(validation_results$process)) {
  cat(sprintf("   ‚Ä¢ Score Ranges Valid: %s\n",
              ifelse(validation_results$process$score_ranges_valid, "‚úÖ", "‚ùå")))
  cat(sprintf("   ‚Ä¢ No Missing Scores: %s\n",
              ifelse(validation_results$process$no_na_scores, "‚úÖ", "‚ùå")))
}

cat("\n")
cat(paste(rep("=", 80), collapse = ""), "\n")
cat("DAII 3.5 PHASE 1 EXECUTION COMPLETE - READY FOR N200 SCALING\n")
cat(paste(rep("=", 80), collapse = ""), "\n")

# Return the final data for further analysis
daii_company_level_data
