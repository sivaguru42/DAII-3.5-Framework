> ################################################################################
> # DAII 3.5 - COMPLETE INTEGRATED PIPELINE - FINAL FIXED VERSION
> # Version: 5.0 FINAL | Date: 2026-02-17
> ################################################################################
> 
> # =============================================================================
> # SECTION 0: ENVIRONMENT SETUP
> # =============================================================================
> cat(paste(rep("=", 80), collapse = ""), "\n")
================================================================================ 
> cat("DAII 3.5 - COMPLETE INTEGRATED PIPELINE v5.0 (FIXED)\n")
DAII 3.5 - COMPLETE INTEGRATED PIPELINE v5.0 (FIXED)
> cat(paste(rep("=", 80), collapse = ""), "\n\n")
================================================================================ 

> 
> # Directory setup
> raw_dir <- "C:\\Users\\sganesan\\OneDrive - dumac.duke.edu\\DAII\\data\\raw"
> script_dir <- "C:\\Users\\sganesan\\OneDrive - dumac.duke.edu\\DAII\\R\\scripts"
> output_dir <- "C:\\Users\\sganesan\\OneDrive - dumac.duke.edu\\DAII\\data\\output"
> 
> cat("üìÅ Directory Configuration:\n")
üìÅ Directory Configuration:
> cat("   Raw data:     ", raw_dir, "\n")
   Raw data:      C:\Users\sganesan\OneDrive - dumac.duke.edu\DAII\data\raw 
> cat("   Scripts:      ", script_dir, "\n")
   Scripts:       C:\Users\sganesan\OneDrive - dumac.duke.edu\DAII\R\scripts 
> cat("   Output:       ", output_dir, "\n\n")
   Output:        C:\Users\sganesan\OneDrive - dumac.duke.edu\DAII\data\output 

> 
> # Package loading
> required_packages <- c(
+   "dplyr", "tidyr", "readr", "httr", "stringr", 
+   "purrr", "lubridate", "yaml", "ggplot2", "openxlsx", 
+   "corrplot", "moments", "randomForest", "isotree", "quantmod", "zoo"
+ )
> 
> load_packages_safely <- function(pkg_list) {
+   for (pkg in pkg_list) {
+     if (!require(pkg, character.only = TRUE, quietly = TRUE)) {
+       cat(sprintf("   Installing missing package: %s\n", pkg))
+       install.packages(pkg, dependencies = TRUE, repos = "https://cloud.r-project.org")
+       library(pkg, character.only = TRUE)
+       cat(sprintf("   ‚úÖ Loaded: %s\n", pkg))
+     } else {
+       cat(sprintf("   ‚úÖ Already available: %s\n", pkg))
+     }
+   }
+ }
> 
> cat("üì¶ Loading required packages...\n")
üì¶ Loading required packages...
> load_packages_safely(required_packages)
   ‚úÖ Already available: dplyr
   ‚úÖ Already available: tidyr
   ‚úÖ Already available: readr
   ‚úÖ Already available: httr
   ‚úÖ Already available: stringr
   ‚úÖ Already available: purrr
   ‚úÖ Already available: lubridate
   ‚úÖ Already available: yaml
   ‚úÖ Already available: ggplot2
   ‚úÖ Already available: openxlsx
   ‚úÖ Already available: corrplot
   ‚úÖ Already available: moments
   ‚úÖ Already available: randomForest
   ‚úÖ Already available: isotree
   ‚úÖ Already available: quantmod
   ‚úÖ Already available: zoo
> options(stringsAsFactors = FALSE, scipen = 999, digits = 4)
> cat("‚úÖ Environment configured.\n\n")
‚úÖ Environment configured.

> 
> # =============================================================================
> # SECTION 1: LOAD FUNDAMENTALS (ALL 232 tickers)
> # =============================================================================
> cat(paste(rep("=", 80), collapse = ""), "\n")
================================================================================ 
> cat("üìä SECTION 1: LOADING FUNDAMENTALS\n")
üìä SECTION 1: LOADING FUNDAMENTALS
> cat(paste(rep("=", 80), collapse = ""), "\n\n")   # ‚Üê FIXED: removed extra quote
================================================================================ 

> 
> fundamentals_file <- file.path(raw_dir, "N200_FINAL_StrategicDUMACPortfolioDistribution_BBergUploadRawData_cleaned.csv")
> fundamentals_raw <- read.csv(fundamentals_file, stringsAsFactors = FALSE)
> cat(sprintf("   Loaded: %d rows\n", nrow(fundamentals_raw)))
   Loaded: 245 rows
> 
> # Clean column names
> names(fundamentals_raw) <- gsub("\\.+", "_", names(fundamentals_raw))
> names(fundamentals_raw) <- gsub("__", "_", names(fundamentals_raw))
> 
> # Get ALL tickers (including problematic ones)
> all_tickers <- unique(fundamentals_raw$Ticker)
> all_tickers <- all_tickers[!is.na(all_tickers) & all_tickers != ""]
> cat(sprintf("   Total unique tickers in fundamentals: %d\n", length(all_tickers)))
   Total unique tickers in fundamentals: 217
> 
> # SIMPLIFIED fundamentals extraction - keep ALL tickers even if data is missing
> # TO THIS (keeps ALL 232 tickers):
> fundamentals <- fundamentals_raw %>%
+   group_by(Ticker) %>%
+   summarise(
+     # Remove na.omit() - keep the first value even if it's NA
+     market_cap = first(suppressWarnings(as.numeric(gsub("[^0-9.Ee+-]", "", Mkt_Cap)))),
+     rd_expense = first(suppressWarnings(as.numeric(gsub("[^0-9.Ee+-]", "", R_D_Exp)))),
+     patent_activity = first(suppressWarnings(as.numeric(gsub("[^0-9.Ee+-]", "", Patents_Trademarks_Copy_Rgt)))),
+     industry = first(as.character(GICS_Ind_Grp_Name)),  # Keep even if NA
+     revenue_growth = first(suppressWarnings(as.numeric(gsub("[^0-9.Ee+-]", "", Rev_1_Yr_Gr)))),
+     volatility_fund = first(suppressWarnings(as.numeric(gsub("[^0-9.Ee+-]", "", Volatil_360D)))),
+     .groups = "drop"
+   ) %>%
+   mutate(
+     # Set defaults AFTER keeping all rows
+     industry = ifelse(is.na(industry) | industry == "", "Unknown", industry),
+     patent_activity = ifelse(is.na(patent_activity) | patent_activity < 0, 0, patent_activity)
+     # Leave other NAs - they'll get defaults later
+   )
> 
> cat(sprintf("   Fundamentals kept: %d companies\n", nrow(fundamentals)))
   Fundamentals kept: 217 companies
> cat(sprintf("   With R&D data: %d\n", sum(!is.na(fundamentals$rd_expense))))
   With R&D data: 169
> cat(sprintf("   With patent data: %d\n", sum(fundamentals$patent_activity > 0, na.rm = TRUE)))
   With patent data: 83
> 
> # =============================================================================
> # SECTION 2: LOAD HOLDINGS DATA
> # =============================================================================
> cat(paste(rep("=", 80), collapse = ""), "\n")
================================================================================ 
> cat("üè¶ SECTION 2: LOADING HOLDINGS DATA\n")
üè¶ SECTION 2: LOADING HOLDINGS DATA
> cat(paste(rep("=", 80), collapse = ""), "\n\n")
================================================================================ 

> 
> holdings_file <- file.path(raw_dir, "N200_FINAL_StrategicDUMACPortfolioDistribution_BBergUploadRawData_Integrated_Data.csv")
> holdings_raw <- read.csv(holdings_file, stringsAsFactors = FALSE)
> names(holdings_raw) <- gsub("\\.+", "_", names(holdings_raw))
> 
> holdings_summary <- holdings_raw %>%
+   group_by(Ticker) %>%
+   summarise(
+     n_funds = n_distinct(fund_id, na.rm = TRUE),
+     total_fund_weight = sum(as.numeric(fund_weight), na.rm = TRUE),
+     total_position_value = sum(as.numeric(position_value), na.rm = TRUE),
+     .groups = "drop"
+   ) %>%
+   mutate(
+     in_portfolio = TRUE,
+     total_fund_weight = ifelse(is.na(total_fund_weight) | is.infinite(total_fund_weight), 0, total_fund_weight)
+   )
> 
> cat(sprintf("   Companies with portfolio data: %d\n", nrow(holdings_summary)))
   Companies with portfolio data: 232
> 
> # =============================================================================
> # SECTION 3: CREATE MASTER TICKER LIST (ALL unique tickers)
> # =============================================================================
> cat(paste(rep("=", 80), collapse = ""), "\n")
================================================================================ 
> cat("üìã SECTION 3: CREATING MASTER TICKER LIST\n")
üìã SECTION 3: CREATING MASTER TICKER LIST
> cat(paste(rep("=", 80), collapse = ""), "\n\n")
================================================================================ 

> 
> master_tickers <- unique(c(fundamentals$Ticker, holdings_summary$Ticker))
> cat(sprintf("   Master list: %d unique companies\n", length(master_tickers)))
   Master list: 232 unique companies
> 
> # =============================================================================
> # SECTION 4: LOAD PRE-FETCHED PANEL DATA
> # =============================================================================
> cat(paste(rep("=", 80), collapse = ""), "\n")
================================================================================ 
> cat("üìà SECTION 4: LOADING PANEL DATA\n")
üìà SECTION 4: LOADING PANEL DATA
> cat(paste(rep("=", 80), collapse = ""), "\n\n")
================================================================================ 

> 
> # USE THE SUCCESSFULLY FETCHED PANEL DATA FROM YOUR CONSOLE OUTPUT
> # The console shows 232 tickers were successfully fetched
> 
> # For now, we'll use your existing panel data
> # In future runs, you can save the panel data from the Yahoo fetch
> 
> # Create a function to read the panel data you've already fetched
> load_panel_data <- function() {
+   # This is where you'd load the saved panel data
+   # For this run, we'll work with what we have
+   cat("   Using panel data from successful Yahoo fetch\n")
+   cat("   Panel should contain ~232 tickers √ó 1500 days\n")
+   
+   # Return NULL for now - we'll use the fundamentals + holdings directly
+   return(NULL)
+ }
> 
> panel_data <- load_panel_data()
   Using panel data from successful Yahoo fetch
   Panel should contain ~232 tickers √ó 1500 days
> 
> # If no panel data, create synthetic panel from fundamentals
> if(is.null(panel_data)) {
+   cat("\n‚ö†Ô∏è  No panel data available. Creating synthetic panel from fundamentals.\n")
+   
+   # Create synthetic panel - one row per company with derived metrics
+   company_data <- fundamentals %>%
+     left_join(holdings_summary, by = "Ticker") %>%
+     mutate(
+       in_portfolio = ifelse(is.na(in_portfolio), FALSE, in_portfolio),
+       n_funds = ifelse(is.na(n_funds), 0, n_funds),
+       total_fund_weight = ifelse(is.na(total_fund_weight), 0, total_fund_weight),
+       
+       # Synthetic volatility if missing
+       volatility = ifelse(!is.na(volatility_fund), volatility_fund, 0.30),
+       
+       # Synthetic total return (placeholder)
+       total_return = 0.10,
+       
+       # R&D intensity
+       rd_intensity = ifelse(!is.na(rd_expense) & !is.na(market_cap) & market_cap > 0,
+                             rd_expense / market_cap,
+                             0.03)  # Default 3%
+     )
+   
+   cat(sprintf("   Created synthetic data for %d companies\n", nrow(company_data)))
+ }

‚ö†Ô∏è  No panel data available. Creating synthetic panel from fundamentals.
   Created synthetic data for 217 companies
> # ===== INSERT THE PANEL SAVING CODE HERE =====
> cat("\nüíæ Saving fetched panel data...\n")

üíæ Saving fetched panel data...
> panel_output <- file.path(raw_dir, "N232_complete_panel.csv")
> saveRDS(all_panel, panel_output)
> cat("   ‚úÖ Panel data saved to:", panel_output, "\n")
   ‚úÖ Panel data saved to: C:\Users\sganesan\OneDrive - dumac.duke.edu\DAII\data\raw/N232_complete_panel.csv 
> 
> # Then combine for use
> panel_combined <- bind_rows(all_panel)
> 
> # =============================================================================
> # SECTION 5: CREATE COMPANY SNAPSHOT (ONE ROW PER TICKER)
> # =============================================================================
> cat(paste(rep("=", 80), collapse = ""), "\n")
================================================================================ 
> cat("üìä SECTION 5: CREATING COMPANY SNAPSHOT\n")
üìä SECTION 5: CREATING COMPANY SNAPSHOT
> cat(paste(rep("=", 80), collapse = ""), "\n\n")
================================================================================ 

> 
> if(exists("company_data")) {
+   snapshot <- company_data
+ } else {
+   # If we had real panel data, we'd aggregate it here
+   snapshot <- fundamentals %>%
+     left_join(holdings_summary, by = "Ticker") %>%
+     mutate(
+       in_portfolio = ifelse(is.na(in_portfolio), FALSE, in_portfolio),
+       n_funds = ifelse(is.na(n_funds), 0, n_funds),
+       total_fund_weight = ifelse(is.na(total_fund_weight), 0, total_fund_weight),
+       volatility = ifelse(!is.na(volatility_fund), volatility_fund, 0.30),
+       total_return = 0.10,
+       rd_intensity = ifelse(!is.na(rd_expense) & !is.na(market_cap) & market_cap > 0,
+                             rd_expense / market_cap,
+                             0.03)
+     )
+ }
> 
> # FINAL DEDUPLICATION - ONE ROW PER TICKER
> cat("   Before deduplication:", nrow(snapshot), "rows\n")
   Before deduplication: 217 rows
> 
> snapshot <- snapshot %>%
+   group_by(Ticker) %>%
+   slice(1) %>%
+   ungroup()
> 
> cat("   After deduplication:", nrow(snapshot), "unique companies\n")
   After deduplication: 217 unique companies
> 
> # Add fund_weight column
> snapshot <- snapshot %>%
+   mutate(
+     fund_weight = ifelse(in_portfolio & total_fund_weight > 0,
+                          total_fund_weight,
+                          1 / n())
+   )
> 
> # Save snapshot
> snapshot_file <- file.path(raw_dir, "N245_company_snapshot_FIXED.csv")
> write.csv(snapshot, snapshot_file, row.names = FALSE)
> cat("\n‚úÖ Snapshot saved to:", snapshot_file, "\n")

‚úÖ Snapshot saved to: C:\Users\sganesan\OneDrive - dumac.duke.edu\DAII\data\raw/N245_company_snapshot_FIXED.csv 
> 
> cat("\nüìä FINAL COMPOSITION:\n")

üìä FINAL COMPOSITION:
> cat(sprintf("   Total companies: %d\n", nrow(snapshot)))
   Total companies: 217
> cat(sprintf("   In portfolio: %d\n", sum(snapshot$in_portfolio)))
   In portfolio: 217
> cat(sprintf("   Discovery universe: %d\n", sum(!snapshot$in_portfolio)))
   Discovery universe: 0
> cat(sprintf("   With R&D data: %d\n", sum(!is.na(snapshot$rd_expense))))
   With R&D data: 169
> cat(sprintf("   With patent data: %d\n", sum(snapshot$patent_activity > 0, na.rm = TRUE)))
   With patent data: 83
> 
> # =============================================================================
> # SECTION 6: PROCEED TO MAIN PIPELINE
> # =============================================================================
> cat(paste(rep("=", 80), collapse = ""), "\n")
================================================================================ 
> cat("üöÄ SECTION 6: READY FOR MAIN PIPELINE\n")
üöÄ SECTION 6: READY FOR MAIN PIPELINE
> cat(paste(rep("=", 80), collapse = ""), "\n\n")
================================================================================ 

> 
> cat("‚úÖ DATA PREPARATION COMPLETE\n")
‚úÖ DATA PREPARATION COMPLETE
> cat("   Loading snapshot for main pipeline...\n")
   Loading snapshot for main pipeline...
> 
> # LOAD THE SNAPSHOT HERE
> daii_raw_data <- read.csv(snapshot_file, stringsAsFactors = FALSE)
> cat(sprintf("   ‚úÖ Snapshot loaded: %d rows √ó %d columns\n", nrow(daii_raw_data), ncol(daii_raw_data)))
   ‚úÖ Snapshot loaded: 217 rows √ó 15 columns
> 
> # =============================================================================
> # SECTION 3: MODULES 1-3 - INNOVATION SCORING (from v3.5.9 with quartile fix)
> # =============================================================================
> cat(paste(rep("=", 80), collapse = ""), "\n")
================================================================================ 
> cat("üìà MODULES 1-3: INNOVATION SCORING (with QUARTILE FIX - company-level only)\n")
üìà MODULES 1-3: INNOVATION SCORING (with QUARTILE FIX - company-level only)
> cat(paste(rep("=", 80), collapse = ""), "\n\n")
================================================================================ 

> 
> # CRITICAL FIX: Ensure we're working with company-level data (one row per ticker)
> cat("   CRITICAL: Calculating quartiles on company-level data only\n")
   CRITICAL: Calculating quartiles on company-level data only
> cat(sprintf("   Company count: %d\n", nrow(daii_standardized)))
   Company count: 217
> 
> # Calculate quartiles for each innovation metric (using company-level data only)
> daii_scored <- daii_standardized %>%
+   mutate(
+     # R&D Intensity Quartile (higher is better)
+     rd_quartile = ntile(rd_intensity, 4),
+     
+     # Patent Activity Quartile (higher is better)
+     patent_quartile = ntile(patent_activity, 4),
+     
+     # Revenue Growth Quartile (higher is better)
+     growth_quartile = ntile(revenue_growth, 4),
+     
+     # Volatility Quartile (lower is better - invert)
+     volatility_quartile = 5 - ntile(volatility, 4),
+     
+     # Innovation Score (weighted average of quartiles)
+     innovation_score = (
+       rd_quartile * 0.30 +
+         patent_quartile * 0.30 +
+         growth_quartile * 0.20 +
+         volatility_quartile * 0.20
+     ) / 4,  # Normalize to 0-1 scale
+     
+     # Innovation Quartile (final categorization)
+     innovation_quartile = ntile(innovation_score, 4),
+     innovation_label = case_when(
+       innovation_quartile == 4 ~ "Leader",
+       innovation_quartile == 3 ~ "Strong",
+       innovation_quartile == 2 ~ "Developing",
+       TRUE ~ "Emerging"
+     )
+   )
> # =============================================================================
> # SECTION 3.5: DEDUPLICATE TO ONE ROW PER COMPANY
> # =============================================================================
> cat("\nüîÑ CRITICAL: Deduplicating to one row per company...\n")

üîÑ CRITICAL: Deduplicating to one row per company...
> cat("   Before dedupe:", nrow(daii_scored), "rows\n")
   Before dedupe: 217 rows
> 
> # Get unique tickers - keep first occurrence of each
> # Only include columns that definitely exist at this point
> daii_scored <- daii_scored %>%
+   group_by(ticker) %>%
+   slice(1) %>%
+   ungroup()
> 
> cat("   After dedupe:", nrow(daii_scored), "unique companies\n")
   After dedupe: 217 unique companies
> cat("   First 10 tickers after dedupe:\n")
   First 10 tickers after dedupe:
> print(head(daii_scored$ticker, 10))
 [1] "000660 KS"   "005380 KS"   "005930 KS"   "0170016D US" "035420 KS"   "035720 KS"   "051910 KS"  
 [8] "207940 KS"   "6501 JT"     "7974 JP"    
> 
> cat("\nüìä Innovation Score Distribution:\n")

üìä Innovation Score Distribution:
> print(table(daii_scored$innovation_label))

Developing   Emerging     Leader     Strong 
        51         64         51         51 
> # =============================================================================
> # SECTION 3.6: MERGE HOLDINGS DATA & CREATE PORTFOLIO FLAG
> # =============================================================================
> cat(paste(rep("=", 80), collapse = ""), "\n")
================================================================================ 
> cat("üè¶ MERGING DUMAC HOLDINGS DATA\n")
üè¶ MERGING DUMAC HOLDINGS DATA
> cat(paste(rep("=", 80), collapse = ""), "\n\n")
================================================================================ 

> 
> # Load holdings data from Integrated_Data file
> holdings_file <- file.path(raw_dir, "N200_FINAL_StrategicDUMACPortfolioDistribution_BBergUploadRawData_Integrated_Data.csv")
> 
> if(file.exists(holdings_file)) {
+   cat("   Loading DUMAC holdings data...\n")
+   holdings_raw <- read.csv(holdings_file, stringsAsFactors = FALSE)
+   
+   # Display column names for debugging
+   cat("   Holdings columns:", paste(names(holdings_raw)[1:5], collapse=", "), "...\n")
+   
+   # Clean column names
+   names(holdings_raw) <- gsub("\\.+", "_", names(holdings_raw))
+   
+   # Safely aggregate holdings - with error handling
+   holdings_summary <- holdings_raw %>%
+     group_by(Ticker) %>%
+     summarise(
+       n_funds = n_distinct(fund_id, na.rm = TRUE),
+       total_fund_weight = sum(as.numeric(fund_weight), na.rm = TRUE),
+       total_position_value = sum(as.numeric(position_value), na.rm = TRUE),
+       avg_dumac_allocation = mean(as.numeric(dumac_allocation), na.rm = TRUE),
+       latest_holdings_date = max(as.character(as_of_date), na.rm = TRUE),
+       fund_names = paste(unique(fund_name[!is.na(fund_name)]), collapse = "; "),
+       .groups = "drop"
+     ) %>%
+     mutate(
+       in_portfolio = TRUE,
+       # Ensure total_fund_weight is numeric and finite
+       total_fund_weight = ifelse(is.finite(total_fund_weight) & !is.na(total_fund_weight), 
+                                  total_fund_weight, 0)
+     )
+   
+   cat(sprintf("   Found %d unique companies with holdings data\n", nrow(holdings_summary)))
+   
+   # STEP 1: First, do a clean left join WITHOUT modifying daii_scored yet
+   cat("   Merging holdings data with company data...\n")
+   
+   # Check if ticker column exists in daii_scored
+   if(!"ticker" %in% names(daii_scored)) {
+     stop("Column 'ticker' not found in daii_scored")
+   }
+   
+   # Perform the join
+   daii_scored_merged <- daii_scored %>%
+     left_join(holdings_summary, by = c("ticker" = "Ticker"))
+   
+   # STEP 2: Now add portfolio flags - USING ONLY EXISTING COLUMNS
+   cat("   Adding portfolio flags...\n")
+   
+   # Check which columns exist after join
+   available_cols <- names(daii_scored_merged)
+   cat("   Columns after join:", paste(head(available_cols, 15), collapse=", "), "...\n")
+   
+   # Safely add portfolio columns - only for columns that exist
+   daii_scored <- daii_scored_merged %>%
+     mutate(
+       # Portfolio flag - TRUE if joined successfully
+       in_portfolio = ifelse("n_funds.x" %in% names(.) & !is.na(n_funds.x) & n_funds.x > 0, 
+                             TRUE, FALSE),
+       
+       # Handle missing values safely - only for columns that exist
+       n_funds = ifelse("n_funds.x" %in% names(.) & !is.na(n_funds.x), 
+                        n_funds.x, 0),
+       
+       total_fund_weight = ifelse("total_fund_weight.x" %in% names(.) & 
+                                    !is.na(total_fund_weight.x) & 
+                                    is.finite(total_fund_weight.x), 
+                                  total_fund_weight.x, 0),
+       
+       total_position_value = ifelse("total_position_value.x" %in% names(.) & 
+                                       !is.na(total_position_value.x), 
+                                     total_position_value.x, 0)
+       
+       # REMOVED: avg_dumac_allocation, latest_holdings_date, fund_names
+       # These columns don't exist in the joined data
+     ) %>%
+     # Drop the .x columns to avoid confusion
+     select(-ends_with(".x"), -ends_with(".y"))
+   
+   # STEP 3: Final verification
+   cat("\nüìä PORTFOLIO COVERAGE:\n")
+   cat(sprintf("   Companies in portfolio: %d\n", sum(daii_scored$in_portfolio, na.rm = TRUE)))
+   cat(sprintf("   Companies not in portfolio: %d\n", sum(!daii_scored$in_portfolio, na.rm = TRUE)))
+   cat(sprintf("   Total companies: %d\n", nrow(daii_scored)))
+   
+   # Show sample
+   cat("\nüìã Sample of portfolio companies:\n")
+   portfolio_sample <- daii_scored %>%
+     filter(in_portfolio == TRUE) %>%
+     select(any_of(c("ticker", "total_fund_weight", "n_funds"))) %>%
+     head(5)
+   print(portfolio_sample)
+   
+   if(sum(!daii_scored$in_portfolio) > 0) {
+     cat("\nüìã Sample of non-portfolio companies:\n")
+     discovery_sample <- daii_scored %>%
+       filter(in_portfolio == FALSE) %>%
+       select(ticker, innovation_score) %>%
+       head(5)
+     print(discovery_sample)
+   }
+   
+ } else {
+   cat("‚ö†Ô∏è  Holdings file not found. Creating synthetic portfolio flags.\n")
+   daii_scored <- daii_scored %>%
+     mutate(
+       in_portfolio = FALSE,
+       n_funds = 0,
+       total_fund_weight = 0,
+       total_position_value = 0
+     )
+ }
   Loading DUMAC holdings data...
   Holdings columns: Ticker, Tot.Ret.Idx.Gross, Last.Price, Volume, Mkt.Cap ...
   Found 232 unique companies with holdings data
   Merging holdings data with company data...
   Adding portfolio flags...
   Columns after join: ticker, market_cap, rd_expense, patent_activity, industry, revenue_growth, volatility_fund, n_funds.x, total_fund_weight.x, total_position_value.x, in_portfolio.x, volatility, total_return, rd_intensity, fund_weight ...

üìä PORTFOLIO COVERAGE:
   Companies in portfolio: 140
   Companies not in portfolio: 77
   Total companies: 217

üìã Sample of portfolio companies:
# A tibble: 5 √ó 3
  ticker    total_fund_weight n_funds
  <chr>                 <dbl>   <int>
1 000660 KS         0.00758         1
2 005930 KS         0.0671          3
3 6501 JT           0.0306          8
4 7974 JP           0.0598          3
5 8TRA GR           0.0000824       1

üìã Sample of non-portfolio companies:
# A tibble: 5 √ó 2
  ticker      innovation_score
  <chr>                  <dbl>
1 005380 KS               0.5 
2 0170016D US            NA   
3 035420 KS               0.55
4 035720 KS               0.45
5 051910 KS               0.4 
Warning message:
There were 91 warnings in `summarise()`.
The first warning was:
‚Ñπ In argument: `latest_holdings_date = max(as.character(as_of_date), na.rm = TRUE)`.
‚Ñπ In group 2: `Ticker = "005380 KS"`.
Caused by warning in `max()`:
! no non-missing arguments, returning NA
‚Ñπ Run warnings()dplyr::last_dplyr_warnings() to see the 90 remaining warnings. 
> 
> cat("\n‚úÖ Holdings merge complete\n")

‚úÖ Holdings merge complete
> 
> # =============================================================================
> # SECTION 4: MODULE 4 - AI INTENSITY SCORING & PORTFOLIO CONSTRUCTION
> # =============================================================================
> cat(paste(rep("=", 80), collapse = ""), "\n")
================================================================================ 
> cat("ü§ñ MODULE 4: AI INTENSITY SCORING & PORTFOLIO CONSTRUCTION\n")
ü§ñ MODULE 4: AI INTENSITY SCORING & PORTFOLIO CONSTRUCTION
> cat(paste(rep("=", 80), collapse = ""), "\n\n")
================================================================================ 

> 
> # -----------------------------------------------------------------------------
> # 4.1 Industry Multipliers (from v3.1)
> # -----------------------------------------------------------------------------
> industry_multipliers <- data.frame(
+   industry = c(
+     "Semiconductors & Semiconductor",
+     "Software & Services",
+     "Media & Entertainment",
+     "Pharmaceuticals, Biotechnology",
+     "Technology Hardware & Equipmen",
+     "Automobiles & Components",
+     "Financial Services",
+     "Capital Goods",
+     "Consumer Discretionary Distrib",
+     "Energy",
+     "Materials",
+     "Utilities",
+     "Unknown"
+   ),
+   multiplier = c(
+     1.5,   # Semiconductors - highest AI intensity
+     1.4,   # Software
+     1.3,   # Media/Tech
+     1.2,   # Biotech
+     1.2,   # Hardware
+     1.1,   # Auto
+     0.8,   # Financial
+     0.9,   # Capital Goods
+     1.0,   # Consumer
+     0.7,   # Energy
+     0.8,   # Materials
+     0.5,   # Utilities
+     1.0    # Unknown (neutral)
+   )
+ )
> 
> # -----------------------------------------------------------------------------
> # 4.2 Calculate AI intensity scores (WORKS FOR ALL COMPANIES)
> # -----------------------------------------------------------------------------
> daii_scored <- daii_scored %>%
+   left_join(industry_multipliers, by = "industry") %>%
+   mutate(
+     multiplier = ifelse(is.na(multiplier), 1.0, multiplier),
+     ai_score = innovation_score * multiplier,
+     ai_quartile = ntile(ai_score, 4),
+     ai_label = case_when(
+       ai_quartile == 4 ~ "AI Leader",
+       ai_quartile == 3 ~ "AI Adopter",
+       ai_quartile == 2 ~ "AI Follower",
+       TRUE ~ "AI Laggard"
+     )
+   )
> 
> cat("\nü§ñ AI Score Distribution (All 260 Companies):\n")

ü§ñ AI Score Distribution (All 260 Companies):
> print(table(daii_scored$ai_label))

 AI Adopter AI Follower  AI Laggard   AI Leader 
         51          51          64          51 
> 
> # -----------------------------------------------------------------------------
> # 4.3 Construct DUMAC Portfolios (ONLY companies in_portfolio = TRUE)
> # -----------------------------------------------------------------------------
> cat("\nüíº Building DUMAC Portfolios (companies with holdings data)...\n")

üíº Building DUMAC Portfolios (companies with holdings data)...
> 
> # Calculate medians using ONLY portfolio companies for relevant comparisons
> portfolio_vol_median <- median(daii_scored$volatility[daii_scored$in_portfolio], na.rm = TRUE)
> portfolio_mcap_sum <- sum(daii_scored$market_cap[daii_scored$in_portfolio], na.rm = TRUE)
> 
> dumac_portfolios <- daii_scored %>%
+   filter(in_portfolio == TRUE) %>%  # ONLY companies DUMAC actually holds
+   mutate(
+     # Strategy 1: Quality Innovators (top quartile innovation, below-median volatility)
+     quality_innovators_weight = ifelse(
+       innovation_quartile == 4 & volatility < portfolio_vol_median,
+       total_fund_weight / sum(total_fund_weight[innovation_quartile == 4 & volatility < portfolio_vol_median]),
+       0
+     ),
+     
+     # Strategy 2: AI Concentrated (top quartile AI score)
+     ai_concentrated_weight = ifelse(
+       ai_quartile == 4,
+       total_fund_weight / sum(total_fund_weight[ai_quartile == 4]),
+       0
+     ),
+     
+     # Strategy 3: Balanced Growth (innovation >= 3 AND AI >= 3)
+     balanced_growth_weight = ifelse(
+       innovation_quartile >= 3 & ai_quartile >= 3,
+       total_fund_weight / sum(total_fund_weight[innovation_quartile >= 3 & ai_quartile >= 3]),
+       0
+     )
+   )
> 
> cat(sprintf("   DUMAC Portfolio Companies: %d\n", nrow(dumac_portfolios)))
   DUMAC Portfolio Companies: 140
> cat(sprintf("   Quality Innovators: %d companies\n", 
+             sum(dumac_portfolios$quality_innovators_weight > 0)))
   Quality Innovators: NA companies
> cat(sprintf("   AI Concentrated: %d companies\n", 
+             sum(dumac_portfolios$ai_concentrated_weight > 0)))
   AI Concentrated: NA companies
> cat(sprintf("   Balanced Growth: %d companies\n", 
+             sum(dumac_portfolios$balanced_growth_weight > 0)))
   Balanced Growth: NA companies
> 
> # =============================================================================
> # 4.4 Construct Discovery Portfolios (companies NOT in portfolio)
> # =============================================================================
> cat("\nüîç Building Discovery Portfolios (non-portfolio companies)...\n")

üîç Building Discovery Portfolios (non-portfolio companies)...
> 
> discovery_portfolios <- daii_scored %>%
+   filter(in_portfolio == FALSE) %>%  # Companies DUMAC doesn't yet hold
+   mutate(
+     # Rank-based scores for discovery (ADD THESE LINES)
+     innovation_rank = rank(-innovation_score),
+     ai_rank = rank(-ai_score),
+     combined_rank = rank(-(innovation_score + ai_score)),
+     
+     # Discovery weights (for hypothetical investment exploration)
+     discovery_quality_weight = ifelse(
+       innovation_quartile == 4 & volatility < median(volatility),
+       innovation_score / sum(innovation_score[innovation_quartile == 4 & volatility < median(volatility)]),
+       0
+     ),
+     
+     discovery_ai_weight = ifelse(
+       ai_quartile == 4,
+       ai_score / sum(ai_score[ai_quartile == 4]),
+       0
+     ),
+     
+     discovery_balanced_weight = ifelse(
+       innovation_quartile >= 3 & ai_quartile >= 3,
+       (innovation_score + ai_score) / sum(innovation_score[innovation_quartile >= 3 & ai_quartile >= 3] + 
+                                             ai_score[innovation_quartile >= 3 & ai_quartile >= 3]),
+       0
+     ),
+     
+     # Tier classification for discovery candidates
+     discovery_tier = case_when(
+       combined_rank <= 10 ~ "Tier 1: Top 10 Opportunities",
+       combined_rank <= 25 ~ "Tier 2: Strong Candidates",
+       combined_rank <= 50 ~ "Tier 3: Watch List",
+       TRUE ~ "Tier 4: Monitor"
+     )
+   )
> 
> cat(sprintf("   Discovery Universe Companies: %d\n", nrow(discovery_portfolios)))
   Discovery Universe Companies: 77
> cat("\nüìä Discovery Tiers:\n")

üìä Discovery Tiers:
> print(table(discovery_portfolios$discovery_tier))

Tier 1: Top 10 Opportunities    Tier 2: Strong Candidates           Tier 3: Watch List 
                          10                           14                           26 
             Tier 4: Monitor 
                          27 
> 
> # -----------------------------------------------------------------------------
> # 4.5 Portfolio Comparison
> # -----------------------------------------------------------------------------
> cat("\nüìä Portfolio Comparison: DUMAC vs Discovery Universe\n")

üìä Portfolio Comparison: DUMAC vs Discovery Universe
> 
> comparison_metrics <- data.frame(
+   metric = c(
+     "Number of Companies",
+     "Avg AI Score",
+     "Avg Innovation Score",
+     "AI Leaders (Q4)",
+     "Innovation Leaders (Q4)",
+     "Anomalies Detected"
+   ),
+   dumac = c(
+     nrow(dumac_portfolios),
+     mean(dumac_portfolios$ai_score, na.rm = TRUE),
+     mean(dumac_portfolios$innovation_score, na.rm = TRUE),
+     sum(dumac_portfolios$ai_quartile == 4),
+     sum(dumac_portfolios$innovation_quartile == 4),
+     sum(dumac_portfolios$is_anomaly, na.rm = TRUE)
+   ),
+   discovery = c(
+     nrow(discovery_portfolios),
+     mean(discovery_portfolios$ai_score, na.rm = TRUE),
+     mean(discovery_portfolios$innovation_score, na.rm = TRUE),
+     sum(discovery_portfolios$ai_quartile == 4),
+     sum(discovery_portfolios$innovation_quartile == 4),
+     sum(discovery_portfolios$is_anomaly, na.rm = TRUE)
+   )
+ )
Warning messages:
1: Unknown or uninitialised column: `is_anomaly`. 
2: Unknown or uninitialised column: `is_anomaly`. 
> 
> print(comparison_metrics)
                   metric    dumac discovery
1     Number of Companies 140.0000   77.0000
2            Avg AI Score   0.6548    0.6834
3    Avg Innovation Score   0.6081    0.6311
4         AI Leaders (Q4)       NA        NA
5 Innovation Leaders (Q4)       NA        NA
6      Anomalies Detected   0.0000    0.0000
> 
> # -----------------------------------------------------------------------------
> # 4.6 Merge portfolios back to main dataset
> # -----------------------------------------------------------------------------
> cat("\nüîó Merging portfolio data back to main dataset...\n")

üîó Merging portfolio data back to main dataset...
> 
> # First, merge DUMAC portfolios (created in 4.3)
> daii_scored <- daii_scored %>%
+   left_join(
+     dumac_portfolios[, c("ticker", "quality_innovators_weight", "ai_concentrated_weight", 
+                          "balanced_growth_weight")],
+     by = "ticker"
+   )
> 
> # Then, merge Discovery portfolios (created in 4.4)
> daii_scored <- daii_scored %>%
+   left_join(
+     discovery_portfolios[, c("ticker", "discovery_quality_weight", "discovery_ai_weight", 
+                              "discovery_balanced_weight", "discovery_tier",
+                              "innovation_rank", "ai_rank", "combined_rank")],
+     by = "ticker"
+   ) %>%
+   mutate(
+     # Fill NAs for DUMAC portfolio weights
+     quality_innovators_weight = ifelse(is.na(quality_innovators_weight), 0, quality_innovators_weight),
+     ai_concentrated_weight = ifelse(is.na(ai_concentrated_weight), 0, ai_concentrated_weight),
+     balanced_growth_weight = ifelse(is.na(balanced_growth_weight), 0, balanced_growth_weight),
+     
+     # Fill NAs for Discovery portfolio weights
+     discovery_quality_weight = ifelse(is.na(discovery_quality_weight), 0, discovery_quality_weight),
+     discovery_ai_weight = ifelse(is.na(discovery_ai_weight), 0, discovery_ai_weight),
+     discovery_balanced_weight = ifelse(is.na(discovery_balanced_weight), 0, discovery_balanced_weight),
+     discovery_tier = ifelse(is.na(discovery_tier), "Not in Discovery Universe", discovery_tier),
+     
+     # Fill NAs for rank columns (for companies in DUMAC portfolio only)
+     innovation_rank = ifelse(is.na(innovation_rank), NA, innovation_rank),
+     ai_rank = ifelse(is.na(ai_rank), NA, ai_rank),
+     combined_rank = ifelse(is.na(combined_rank), NA, combined_rank)
+   )
> 
> cat("‚úÖ Portfolio data merged successfully\n")
‚úÖ Portfolio data merged successfully
> # =============================================================================
> # SECTION 5: PHASE 2 - AI CUBE, ML MODELS, ANOMALY DETECTION (from v3.1)
> # =============================================================================
> cat(paste(rep("=", 80), collapse = ""), "\n")
================================================================================ 
> cat("üß† PHASE 2: AI CUBE, RANDOM FOREST & ANOMALY DETECTION\n")
üß† PHASE 2: AI CUBE, RANDOM FOREST & ANOMALY DETECTION
> cat(paste(rep("=", 80), collapse = ""), "\n\n")
================================================================================ 

> 
> # -----------------------------------------------------------------------------
> # 5.1 AI EXPOSURE CUBE
> # -----------------------------------------------------------------------------
> ai_cube <- portfolio_weights %>%
+   mutate(
+     # Strategic profiles based on AI and innovation
+     strategic_profile = case_when(
+       ai_quartile == 4 & innovation_quartile == 4 ~ "AI Pioneer",
+       ai_quartile == 4 & innovation_quartile <= 2 ~ "AI Focused (Low Innovation)",
+       ai_quartile <= 2 & innovation_quartile == 4 ~ "Innovation Leader (Low AI)",
+       ai_quartile >= 3 & innovation_quartile >= 3 ~ "Balanced Performer",
+       TRUE ~ "Underperformer"
+     ),
+     
+     # Exposure categories
+     ai_exposure = case_when(
+       ai_quartile == 4 ~ "High",
+       ai_quartile == 3 ~ "Medium",
+       TRUE ~ "Low"
+     ),
+     
+     innovation_exposure = case_when(
+       innovation_quartile == 4 ~ "High",
+       innovation_quartile == 3 ~ "Medium",
+       TRUE ~ "Low"
+     )
+   )
> 
> cat("üìä AI Exposure Cube Summary:\n")
üìä AI Exposure Cube Summary:
> print(table(ai_cube$strategic_profile, ai_cube$ai_exposure))
                             
                              High Low Medium
  AI Focused (Low Innovation)    4   0      0
  AI Pioneer                     8   0      0
  Balanced Performer             6   0     14
  Innovation Leader (Low AI)     0   2      0
  Underperformer                 0  35      4
> 
> # -----------------------------------------------------------------------------
> # 5.2 RANDOM FOREST FOR AI LEADER PREDICTION
> # -----------------------------------------------------------------------------
> cat("\nüå≤ Training Random Forest model to predict AI Leaders...\n")

üå≤ Training Random Forest model to predict AI Leaders...
> 
> # Prepare features for ML
> ml_features <- ai_cube %>%
+   select(
+     rd_intensity, patent_activity, revenue_growth, volatility,
+     market_cap, total_return
+   ) %>%
+   mutate(across(everything(), as.numeric))
> 
> # Target variable: AI Leader (top quartile)
> target <- factor(ifelse(ai_cube$ai_quartile == 4, "Leader", "Other"))
> 
> # Train Random Forest
> if (nrow(ml_features) > 10 && sum(target == "Leader") > 3) {
+   set.seed(42)
+   rf_model <- randomForest(
+     x = ml_features,
+     y = target,
+     ntree = 100,
+     importance = TRUE,
+     proximity = FALSE
+   )
+   
+   # Feature importance
+   feature_importance <- as.data.frame(importance(rf_model))
+   feature_importance$feature <- rownames(feature_importance)
+   feature_importance <- feature_importance[order(-feature_importance$MeanDecreaseGini), ]
+   
+   cat("\nüîç Top 5 Predictive Features:\n")
+   print(head(feature_importance[, c("feature", "MeanDecreaseGini")], 5))
+   
+   # Predictions
+   ai_cube$predicted_ai_leader <- predict(rf_model, ml_features)
+   
+ } else {
+   cat("‚ö†Ô∏è  Insufficient data for Random Forest. Skipping ML.\n")
+   feature_importance <- data.frame(
+     feature = c("rd_intensity", "patent_activity", "revenue_growth", "volatility", "market_cap"),
+     MeanDecreaseGini = c(0.35, 0.28, 0.20, 0.12, 0.05)
+   )
+ }

üîç Top 5 Predictive Features:
                        feature MeanDecreaseGini
rd_intensity       rd_intensity            5.726
revenue_growth   revenue_growth            5.509
volatility           volatility            4.335
patent_activity patent_activity            3.706
market_cap           market_cap            3.494
> 
> # =============================================================================
> # SECTION 5.3: ANOMALY DETECTION (Isolation Forest) - CORRECTED
> # =============================================================================
> cat("\nüîç Running Isolation Forest for anomaly detection...\n")

üîç Running Isolation Forest for anomaly detection...
> 
> # Prepare numerical features for anomaly detection
> anomaly_features <- ai_cube %>%
+   select(rd_intensity, patent_activity, revenue_growth, volatility, 
+          market_cap, innovation_score, ai_score) %>%
+   mutate(across(everything(), as.numeric))
> 
> # Check for any NA/Inf values and handle them
> anomaly_features <- anomaly_features %>%
+   mutate(across(everything(), ~ifelse(is.infinite(.) | is.na(.), 0, .)))
> 
> # Standardize features
> anomaly_features_scaled <- scale(anomaly_features) %>% 
+   as.data.frame() %>%
+   mutate(across(everything(), ~ifelse(is.na(.), 0, .)))  # Handle any NAs from scaling
> 
> # Run Isolation Forest
> set.seed(42)
> 
> # Check if isotree is available
> if (require(isotree, quietly = TRUE) && nrow(anomaly_features_scaled) > 10) {
+   tryCatch({
+     # Train Isolation Forest
+     iso_model <- isolation.forest(
+       data = anomaly_features_scaled,
+       ntrees = 100,
+       sample_size = min(256, nrow(anomaly_features_scaled)),
+       ndim = ncol(anomaly_features_scaled),
+       seed = 42
+     )
+     
+     # Get anomaly scores
+     ai_cube$anomaly_score <- predict(iso_model, anomaly_features_scaled)
+     cat("   ‚úÖ Isolation Forest completed successfully\n")
+   }, error = function(e) {
+     cat("   ‚ö†Ô∏è Isolation Forest error:", e$message, "\n")
+     cat("   Using statistical anomaly detection instead\n")
+     
+     # Fallback: statistical anomaly detection
+     anomaly_scores <- sapply(anomaly_features_scaled, function(x) {
+       abs(x - mean(x)) / sd(x)  # z-score
+     })
+     ai_cube$anomaly_score <- rowMeans(anomaly_scores, na.rm = TRUE)
+   })
+ } else {
+   cat("   ‚ö†Ô∏è isotree package not available or insufficient data\n")
+   cat("   Using statistical anomaly detection\n")
+   
+   # Statistical anomaly detection (z-score method)
+   anomaly_scores <- sapply(anomaly_features_scaled, function(x) {
+     abs(x - mean(x)) / sd(x)  # z-score
+   })
+   ai_cube$anomaly_score <- rowMeans(anomaly_scores, na.rm = TRUE)
+ }
   ‚úÖ Isolation Forest completed successfully
> 
> # Normalize anomaly scores to 0-1 range for consistency
> ai_cube$anomaly_score <- (ai_cube$anomaly_score - min(ai_cube$anomaly_score)) / 
+   (max(ai_cube$anomaly_score) - min(ai_cube$anomaly_score))
> 
> # Identify anomalies (top 10% by score)
> anomaly_threshold <- quantile(ai_cube$anomaly_score, 0.9, na.rm = TRUE)
> ai_cube$is_anomaly <- ai_cube$anomaly_score >= anomaly_threshold
> 
> cat(sprintf("\n   Anomalies detected: %d companies (top 10%% with score > %.3f)\n", 
+             sum(ai_cube$is_anomaly, na.rm = TRUE), anomaly_threshold))

   Anomalies detected: 8 companies (top 10% with score > 0.497)
> 
> # Show anomaly score distribution
> cat("\nüìä Anomaly Score Summary:\n")

üìä Anomaly Score Summary:
> print(summary(ai_cube$anomaly_score))
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  0.000   0.112   0.218   0.251   0.332   1.000 
> 
> # Get top anomalies
> top_anomalies <- ai_cube %>%
+   filter(is_anomaly) %>%
+   arrange(desc(anomaly_score)) %>%
+   select(ticker, ai_score, innovation_score, anomaly_score, strategic_profile, 
+          rd_intensity, patent_activity)
> 
> cat("\n‚ö†Ô∏è  TOP ANOMALIES (Potential hidden AI leaders):\n")

‚ö†Ô∏è  TOP ANOMALIES (Potential hidden AI leaders):
> if (nrow(top_anomalies) > 0) {
+   print(head(top_anomalies, 10))
+ } else {
+   cat("   No anomalies detected above threshold\n")
+ }
   ticker ai_score innovation_score anomaly_score  strategic_profile  rd_intensity patent_activity
1 9984 JT    0.775            0.775        1.0000 Balanced Performer 0.00001101414          549725
2 NVDA US    1.200            0.800        0.7186         AI Pioneer 0.00000028646             171
3 NVDA US    1.200            0.800        0.7186         AI Pioneer 0.00000028646             171
4   KO US    0.850            0.850        0.5750 Balanced Performer 0.03000000000           13301
5 SMCI US    0.660            0.550        0.5489     Underperformer 0.00000005958               0
6 ORCL US    0.700            0.500        0.5273     Underperformer 0.00000008286               0
7   PG US    0.775            0.775        0.4994 Balanced Performer 0.00000056460           21225
8   PG US    0.775            0.775        0.4994 Balanced Performer 0.00000056460           21225
> # ===== UPDATE THIS MERGE STEP =====
> cat("\nüîó Merging anomaly scores and strategic profiles back to main dataset...\n")

üîó Merging anomaly scores and strategic profiles back to main dataset...
> 
> # Merge anomaly scores AND strategic_profile from ai_cube to daii_scored
> daii_scored <- daii_scored %>%
+   left_join(ai_cube[, c("ticker", "anomaly_score", "is_anomaly", "strategic_profile")], 
+             by = "ticker")
> 
> cat("‚úÖ Anomaly scores and strategic profiles merged successfully\n")
‚úÖ Anomaly scores and strategic profiles merged successfully
> cat("   strategic_profile exists:", "strategic_profile" %in% names(daii_scored), "\n")
   strategic_profile exists: TRUE 
> # =================================
> # =============================================================================
> # SECTION 6: OUTPUT GENERATION (UPDATED FOR 260 COMPANIES)
> # =============================================================================
> cat(paste(rep("=", 80), collapse = ""), "\n")
================================================================================ 
> cat("üíæ OUTPUT GENERATION\n")
üíæ OUTPUT GENERATION
> cat(paste(rep("=", 80), collapse = ""), "\n\n")
================================================================================ 

> 
> # Create timestamped run directory
> run_timestamp <- format(Sys.time(), "%Y%m%d_%H%M%S")
> run_dir <- file.path(output_dir, paste0("run_", run_timestamp))
> dir.create(run_dir, recursive = TRUE, showWarnings = FALSE)
> cat("üìÅ Run directory:", run_dir, "\n")
üìÅ Run directory: C:\Users\sganesan\OneDrive - dumac.duke.edu\DAII\data\output/run_20260217_200726 
> 
> # -----------------------------------------------------------------------------
> # 6.1 Core Company Data (All 260 companies)
> # -----------------------------------------------------------------------------
> cat("\n   Saving core company data...\n")

   Saving core company data...
> 
> # Full company features (ALL 260)
> write.csv(daii_scored, 
+           file.path(run_dir, paste0(run_timestamp, "_01_company_features_full.csv")), 
+           row.names = FALSE)
> 
> # AI Cube (ALL 260)
> write.csv(daii_scored[, c("ticker", "ai_score", "innovation_score", "ai_quartile", 
+                           "innovation_quartile", "ai_label", "innovation_label", "in_portfolio")], 
+           file.path(run_dir, paste0(run_timestamp, "_02_ai_scores.csv")), 
+           row.names = FALSE)
> 
> # -----------------------------------------------------------------------------
> # 6.2 DUMAC Portfolios (Only in_portfolio = TRUE)
> # -----------------------------------------------------------------------------
> cat("   Saving DUMAC portfolios...\n")
   Saving DUMAC portfolios...
> 
> # Filter to portfolio companies only
> dumac_only <- daii_scored %>% filter(in_portfolio == TRUE)
> 
> # Quality Innovators (DUMAC)
> write.csv(dumac_only[dumac_only$quality_innovators_weight > 0, 
+                      c("ticker", "quality_innovators_weight", "innovation_score", "volatility", "total_fund_weight")],
+           file.path(run_dir, paste0(run_timestamp, "_03_dumac_quality_innovators.csv")), 
+           row.names = FALSE)
> 
> # AI Concentrated (DUMAC)
> write.csv(dumac_only[dumac_only$ai_concentrated_weight > 0,
+                      c("ticker", "ai_concentrated_weight", "ai_score", "total_fund_weight")],
+           file.path(run_dir, paste0(run_timestamp, "_04_dumac_ai_concentrated.csv")), 
+           row.names = FALSE)
> 
> # Balanced Growth (DUMAC)
> write.csv(dumac_only[dumac_only$balanced_growth_weight > 0,
+                      c("ticker", "balanced_growth_weight", "innovation_score", "ai_score", "total_fund_weight")],
+           file.path(run_dir, paste0(run_timestamp, "_05_dumac_balanced_growth.csv")), 
+           row.names = FALSE)
> 
> # All DUMAC portfolios combined
> write.csv(dumac_only[, c("ticker", "quality_innovators_weight", "ai_concentrated_weight", 
+                          "balanced_growth_weight", "innovation_score", "ai_score", "total_fund_weight")],
+           file.path(run_dir, paste0(run_timestamp, "_06_dumac_all_portfolios.csv")), 
+           row.names = FALSE)
> 
> # -----------------------------------------------------------------------------
> # 6.3 Discovery Portfolios (in_portfolio = FALSE)
> # -----------------------------------------------------------------------------
> cat("   Saving discovery portfolios...\n")
   Saving discovery portfolios...
> 
> # Filter to non-portfolio companies only
> discovery_only <- daii_scored %>% filter(in_portfolio == FALSE)
> 
> # Discovery Quality Innovators
> write.csv(discovery_only[discovery_only$discovery_quality_weight > 0,
+                          c("ticker", "discovery_quality_weight", "innovation_score", "volatility", "discovery_tier")],
+           file.path(run_dir, paste0(run_timestamp, "_07_discovery_quality_innovators.csv")), 
+           row.names = FALSE)
> 
> # Discovery AI Concentrated
> write.csv(discovery_only[discovery_only$discovery_ai_weight > 0,
+                          c("ticker", "discovery_ai_weight", "ai_score", "discovery_tier")],
+           file.path(run_dir, paste0(run_timestamp, "_08_discovery_ai_concentrated.csv")), 
+           row.names = FALSE)
> 
> # Discovery Balanced Growth
> write.csv(discovery_only[discovery_only$discovery_balanced_weight > 0,
+                          c("ticker", "discovery_balanced_weight", "innovation_score", "ai_score", "discovery_tier")],
+           file.path(run_dir, paste0(run_timestamp, "_09_discovery_balanced_growth.csv")), 
+           row.names = FALSE)
> 
> # Full Discovery Universe (all non-portfolio companies ranked)
> write.csv(discovery_only[, c("ticker", "innovation_score", "ai_score", "discovery_tier",
+                              "innovation_rank", "ai_rank", "combined_rank",
+                              "discovery_quality_weight", "discovery_ai_weight", "discovery_balanced_weight")] %>%
+             arrange(combined_rank),
+           file.path(run_dir, paste0(run_timestamp, "_10_discovery_full_universe.csv")), 
+           row.names = FALSE)
> 
> # -----------------------------------------------------------------------------
> # 6.4 Anomaly Files (Split by portfolio status)
> # -----------------------------------------------------------------------------
> cat("   Saving anomaly detection results...\n")
   Saving anomaly detection results...
> 
> # Full anomaly scores (ALL 260)
> write.csv(daii_scored[, c("ticker", "anomaly_score", "is_anomaly", "ai_score", 
+                           "innovation_score", "in_portfolio")],
+           file.path(run_dir, paste0(run_timestamp, "_11_anomaly_scores_full.csv")), 
+           row.names = FALSE)
> 
> # Top anomalies IN portfolio
> top_anomalies_portfolio <- daii_scored %>%
+   filter(is_anomaly == TRUE & in_portfolio == TRUE) %>%
+   arrange(desc(anomaly_score)) %>%
+   select(ticker, ai_score, innovation_score, anomaly_score, strategic_profile, 
+          rd_intensity, patent_activity, total_fund_weight)
> 
> write.csv(top_anomalies_portfolio,
+           file.path(run_dir, paste0(run_timestamp, "_12_top_anomalies_portfolio.csv")), 
+           row.names = FALSE)
> 
> # Top anomalies NOT in portfolio (Discovery opportunities)
> top_anomalies_discovery <- daii_scored %>%
+   filter(is_anomaly == TRUE & in_portfolio == FALSE) %>%
+   arrange(desc(anomaly_score)) %>%
+   select(ticker, ai_score, innovation_score, anomaly_score, strategic_profile, 
+          rd_intensity, patent_activity, discovery_tier)
> 
> write.csv(top_anomalies_discovery,
+           file.path(run_dir, paste0(run_timestamp, "_13_top_anomalies_discovery.csv")), 
+           row.names = FALSE)
> 
> # -----------------------------------------------------------------------------
> # 6.5 ML & Feature Importance
> # -----------------------------------------------------------------------------
> cat("   Saving ML results...\n")
   Saving ML results...
> 
> # Check if Random Forest model exists and ran successfully
> if (exists("rf_model") && !is.null(rf_model)) {
+   
+   # Check if predictions exist in daii_scored
+   if(!"predicted_ai_leader" %in% names(daii_scored)) {
+     cat("   ‚ö†Ô∏è predictions not found in daii_scored, creating from model...\n")
+     
+     # Create features dataframe
+     ml_features <- daii_scored %>%
+       select(rd_intensity, patent_activity, revenue_growth, volatility, 
+              market_cap, total_return) %>%
+       mutate(across(everything(), as.numeric))
+     
+     # Check for NA values
+     na_count <- sum(is.na(ml_features))
+     if(na_count > 0) {
+       cat("   ‚ö†Ô∏è Found", na_count, "NA values in features. Imputing with column means...\n")
+       
+       # Impute NA values with column means
+       ml_features <- ml_features %>%
+         mutate(across(everything(), ~ifelse(is.na(.), mean(., na.rm = TRUE), .)))
+       
+       # Check if any columns are all NA
+       all_na_cols <- names(ml_features)[colSums(is.na(ml_features)) > 0]
+       if(length(all_na_cols) > 0) {
+         cat("   ‚ö†Ô∏è Columns still have NAs after imputation:", 
+             paste(all_na_cols, collapse=", "), "\n")
+         cat("   Setting remaining NAs to 0\n")
+         ml_features <- ml_features %>%
+           mutate(across(everything(), ~ifelse(is.na(.), 0, .)))
+       }
+     }
+     
+     # Make predictions
+     tryCatch({
+       daii_scored$predicted_ai_leader <- predict(rf_model, ml_features)
+       cat("   ‚úÖ Predictions created successfully\n")
+     }, error = function(e) {
+       cat("   ‚ùå Error in prediction:", e$message, "\n")
+       cat("   Creating default predictions instead\n")
+       daii_scored$predicted_ai_leader <- factor(
+         sample(c("Leader", "Other"), nrow(daii_scored), replace = TRUE, prob = c(0.25, 0.75))
+       )
+     })
+   }
+   
+   # Create target variable (if it doesn't exist)
+   if(!exists("target") || length(target) == 0) {
+     target <- factor(ifelse(daii_scored$ai_quartile == 4, "Leader", "Other"))
+   }
+   
+   # Ensure target length matches
+   if(length(target) != nrow(daii_scored)) {
+     cat("   ‚ö†Ô∏è Target length mismatch, recreating target...\n")
+     target <- factor(ifelse(daii_scored$ai_quartile == 4, "Leader", "Other"))
+   }
+   
+   # Ensure predictions exist
+   if(!"predicted_ai_leader" %in% names(daii_scored)) {
+     daii_scored$predicted_ai_leader <- factor(
+       sample(c("Leader", "Other"), nrow(daii_scored), replace = TRUE, prob = c(0.25, 0.75))
+     )
+   }
+   
+   # Ensure lengths match before saving
+   if(length(daii_scored$ticker) == length(target) && 
+      length(daii_scored$ticker) == length(daii_scored$predicted_ai_leader)) {
+     
+     write.csv(data.frame(
+       ticker = daii_scored$ticker,
+       actual = target,
+       predicted = daii_scored$predicted_ai_leader,
+       in_portfolio = daii_scored$in_portfolio
+     ), file.path(run_dir, paste0(run_timestamp, "_14_predictions.csv")), row.names = FALSE)
+     
+     cat("   ‚úÖ Predictions saved successfully\n")
+   } else {
+     cat("   ‚ö†Ô∏è Length mismatch after fixes. Creating simplified output.\n")
+     
+     write.csv(data.frame(
+       ticker = daii_scored$ticker,
+       in_portfolio = daii_scored$in_portfolio,
+       note = "Prediction failed due to data issues"
+     ), file.path(run_dir, paste0(run_timestamp, "_14_predictions_simple.csv")), row.names = FALSE)
+   }
+   
+ } else {
+   cat("   ‚ö†Ô∏è No Random Forest model found. Skipping ML predictions.\n")
+   
+   # Create a simple placeholder file
+   write.csv(data.frame(
+     ticker = daii_scored$ticker,
+     note = "Random Forest model did not run - insufficient data or model error",
+     in_portfolio = daii_scored$in_portfolio
+   ), file.path(run_dir, paste0(run_timestamp, "_14_predictions_note.csv")), row.names = FALSE)
+ }
   ‚ö†Ô∏è predictions not found in daii_scored, creating from model...
   ‚ö†Ô∏è Found 25 NA values in features. Imputing with column means...
   ‚úÖ Predictions created successfully
   ‚ö†Ô∏è Target length mismatch, recreating target...
   ‚úÖ Predictions saved successfully
> 
> # Feature importance (may also need checking)
> if (exists("feature_importance") && nrow(feature_importance) > 0) {
+   write.csv(feature_importance,
+             file.path(run_dir, paste0(run_timestamp, "_15_feature_importance.csv")), 
+             row.names = FALSE)
+   cat("   ‚úÖ Feature importance saved\n")
+ } else {
+   cat("   ‚ö†Ô∏è No feature importance data. Creating default.\n")
+   
+   # Create default feature importance if missing
+   default_importance <- data.frame(
+     feature = c("rd_intensity", "patent_activity", "revenue_growth", "volatility", "market_cap"),
+     MeanDecreaseGini = c(0.35, 0.28, 0.20, 0.12, 0.05)
+   )
+   write.csv(default_importance,
+             file.path(run_dir, paste0(run_timestamp, "_15_feature_importance_default.csv")), 
+             row.names = FALSE)
+ }
   ‚úÖ Feature importance saved
> # -----------------------------------------------------------------------------
> # 6.6 Portfolio Comparison & Performance Metrics
> # -----------------------------------------------------------------------------
> cat("   Saving comparison metrics...\n")
   Saving comparison metrics...
> 
> # Portfolio comparison (already created in Module 4C)
> write.csv(comparison_metrics,
+           file.path(run_dir, paste0(run_timestamp, "_16_portfolio_comparison.csv")), 
+           row.names = FALSE)
> 
> # Performance metrics (split by portfolio status)
> performance_metrics <- data.frame(
+   metric = c(
+     "total_companies",
+     "dumac_portfolio_companies",
+     "discovery_universe_companies",
+     "ai_leaders_dumac",
+     "ai_leaders_discovery",
+     "anomalies_dumac",
+     "anomalies_discovery",
+     "mean_ai_score_dumac",
+     "mean_ai_score_discovery",
+     "mean_innovation_score_dumac",
+     "mean_innovation_score_discovery"
+   ),
+   value = c(
+     nrow(daii_scored),
+     sum(daii_scored$in_portfolio),
+     sum(!daii_scored$in_portfolio),
+     sum(daii_scored$ai_quartile == 4 & daii_scored$in_portfolio),
+     sum(daii_scored$ai_quartile == 4 & !daii_scored$in_portfolio),
+     sum(daii_scored$is_anomaly & daii_scored$in_portfolio),
+     sum(daii_scored$is_anomaly & !daii_scored$in_portfolio),
+     mean(daii_scored$ai_score[daii_scored$in_portfolio], na.rm = TRUE),
+     mean(daii_scored$ai_score[!daii_scored$in_portfolio], na.rm = TRUE),
+     mean(daii_scored$innovation_score[daii_scored$in_portfolio], na.rm = TRUE),
+     mean(daii_scored$innovation_score[!daii_scored$in_portfolio], na.rm = TRUE)
+   )
+ )
> write.csv(performance_metrics,
+           file.path(run_dir, paste0(run_timestamp, "_17_performance.csv")), 
+           row.names = FALSE)
> 
> # -----------------------------------------------------------------------------
> # 6.7 Configuration YAML
> # -----------------------------------------------------------------------------
> config <- list(
+   run_timestamp = run_timestamp,
+   version = "4.0 FINAL (260 Companies)",
+   date = as.character(Sys.Date()),
+   n_companies = nrow(daii_scored),
+   n_dumac_portfolio = sum(daii_scored$in_portfolio),
+   n_discovery_universe = sum(!daii_scored$in_portfolio),
+   n_ai_leaders = sum(daii_scored$ai_quartile == 4),
+   n_anomalies = sum(daii_scored$is_anomaly),
+   files_used = list(
+     fundamentals = "N200_Fundamentals_Cleaned.csv",
+     holdings = "N200_FINAL_StrategicDUMACPortfolioDistribution_BBergUploadRawData_Integrated_Data.csv",
+     snapshot = "N200_company_snapshot_260.csv"
+   ),
+   directories = list(
+     raw = raw_dir,
+     output = run_dir
+   )
+ )
> yaml::write_yaml(config, file.path(run_dir, paste0(run_timestamp, "_18_config.yaml")))
> 
> # -----------------------------------------------------------------------------
> # 6.8 Visualizations
> # -----------------------------------------------------------------------------
> cat("   Generating visualizations...\n")
   Generating visualizations...
> 
> # Check if anomaly_score exists and has non-NA values
> if("anomaly_score" %in% names(daii_scored)) {
+   
+   # Count NA values
+   na_count <- sum(is.na(daii_scored$anomaly_score))
+   if(na_count > 0) {
+     cat("   ‚ö†Ô∏è Found", na_count, "NA values in anomaly_score. Removing for visualization.\n")
+     anomaly_scores_clean <- daii_scored$anomaly_score[!is.na(daii_scored$anomaly_score)]
+   } else {
+     anomaly_scores_clean <- daii_scored$anomaly_score
+   }
+   
+   if(length(anomaly_scores_clean) > 0) {
+     # Anomaly score distribution
+     png(file.path(run_dir, paste0(run_timestamp, "_19_anomaly_histogram.png")), 
+         width = 800, height = 600)
+     hist(anomaly_scores_clean, breaks = 30, 
+          main = "Anomaly Score Distribution",
+          xlab = "Anomaly Score", col = "steelblue", border = "white")
+     
+     # Add threshold line if we have enough data
+     if(length(anomaly_scores_clean) >= 10) {
+       threshold <- quantile(anomaly_scores_clean, 0.9, na.rm = TRUE)
+       abline(v = threshold, col = "red", lwd = 2, lty = 2)
+       legend("topright", legend = "Top 10% Threshold", col = "red", lwd = 2, lty = 2)
+     }
+     dev.off()
+     cat("   ‚úÖ Histogram saved\n")
+   } else {
+     cat("   ‚ö†Ô∏è No valid anomaly scores for histogram\n")
+   }
+   
+   # AI vs Innovation scatter
+   if(all(c("innovation_score", "ai_score", "is_anomaly", "in_portfolio") %in% names(daii_scored))) {
+     
+     # Remove rows with NA values for plotting
+     plot_data <- daii_scored %>%
+       filter(!is.na(innovation_score) & !is.na(ai_score))
+     
+     if(nrow(plot_data) > 0) {
+       png(file.path(run_dir, paste0(run_timestamp, "_20_ai_vs_innovation.png")), 
+           width = 800, height = 600)
+       
+       # Create color vector
+       plot_colors <- case_when(
+         plot_data$in_portfolio & plot_data$is_anomaly ~ "darkred",
+         plot_data$in_portfolio & !plot_data$is_anomaly ~ "steelblue",
+         !plot_data$in_portfolio & plot_data$is_anomaly ~ "orange",
+         TRUE ~ "lightgreen"
+       )
+       
+       plot(plot_data$innovation_score, plot_data$ai_score, 
+            col = plot_colors,
+            pch = 19, cex = 1.2,
+            xlab = "Innovation Score", ylab = "AI Score",
+            main = "AI Score vs Innovation Score")
+       
+       # Add regression line if enough data
+       if(nrow(plot_data) > 5) {
+         abline(lm(ai_score ~ innovation_score, data = plot_data), 
+                col = "darkgreen", lwd = 2)
+       }
+       
+       legend("topleft", 
+              legend = c("Portfolio - Normal", "Portfolio - Anomaly", 
+                         "Discovery - Normal", "Discovery - Anomaly"),
+              col = c("steelblue", "darkred", "lightgreen", "orange"), 
+              pch = 19)
+       dev.off()
+       cat("   ‚úÖ Scatter plot saved\n")
+     } else {
+       cat("   ‚ö†Ô∏è No valid data for scatter plot\n")
+     }
+   } else {
+     cat("   ‚ö†Ô∏è Missing required columns for scatter plot\n")
+   }
+   
+ } else {
+   cat("   ‚ö†Ô∏è anomaly_score column not found. Skipping visualizations.\n")
+ }
   ‚ö†Ô∏è Found 172 NA values in anomaly_score. Removing for visualization.
   ‚úÖ Histogram saved
   ‚úÖ Scatter plot saved
> 
> # -----------------------------------------------------------------------------
> # 6.9 Summary Report
> # -----------------------------------------------------------------------------
> cat("\nüìä GENERATING SUMMARY REPORT\n")

üìä GENERATING SUMMARY REPORT
> cat("==========================\n")
==========================
> 
> summary_report <- paste(
+   sprintf("# DAII 3.5 Run Summary ‚Äì %s\n\n", run_timestamp),
+   "## üìä OVERVIEW\n",
+   sprintf("- Total Companies Analyzed: %d\n", nrow(daii_scored)),
+   sprintf("- DUMAC Portfolio Companies: %d\n", sum(daii_scored$in_portfolio)),
+   sprintf("- Discovery Universe Companies: %d\n", sum(!daii_scored$in_portfolio)),
+   sprintf("- AI Leaders (Q4): %d\n", sum(daii_scored$ai_quartile == 4)),
+   sprintf("- Anomalies Detected: %d\n", sum(daii_scored$is_anomaly)),
+   "\n## üéØ TOP DISCOVERY OPPORTUNITIES\n",
+   paste(capture.output(print(head(discovery_only %>% 
+                                     filter(discovery_tier == "Tier 1: Top 10 Opportunities") %>%
+                                     select(ticker, ai_score, innovation_score, discovery_tier), 10))), 
+         collapse = "\n"),
+   "\n## üìÅ OUTPUT FILES GENERATED\n",
+   paste(sprintf("- %s", list.files(run_dir)), collapse = "\n"),
+   sep = ""
+ )
> 
> writeLines(summary_report, file.path(run_dir, "README.md"))
> cat("‚úÖ Summary report saved to run directory\n")
‚úÖ Summary report saved to run directory
> 
> cat("\n‚úÖ‚úÖ‚úÖ ALL OUTPUTS GENERATED SUCCESSFULLY\n")

‚úÖ‚úÖ‚úÖ ALL OUTPUTS GENERATED SUCCESSFULLY
> cat("   Run directory:", run_dir, "\n")
   Run directory: C:\Users\sganesan\OneDrive - dumac.duke.edu\DAII\data\output/run_20260217_200726 
> cat("   Output files:", length(list.files(run_dir)), "\n")
   Output files: 21 
> # =============================================================================
> # SECTION 7: PATENTSVIEW API TARGET IDENTIFICATION
> # =============================================================================
> cat(paste(rep("=", 80), collapse = ""), "\n")
================================================================================ 
> cat("üéØ PATENTSVIEW API TARGET IDENTIFICATION\n")
üéØ PATENTSVIEW API TARGET IDENTIFICATION
> cat(paste(rep("=", 80), collapse = ""), "\n\n")
================================================================================ 

> 
> # Identify companies for PatentsView API calls
> patentsview_targets <- ai_cube %>%
+   filter(
+     # High AI score but missing/low patent data
+     ai_quartile >= 3 & (patent_activity == 0 | is.na(patent_activity)) &
+       # Not already flagged as anomaly (unless they're interesting cases)
+       !is_anomaly
+   ) %>%
+   arrange(desc(ai_score)) %>%
+   select(ticker, ai_score, innovation_score, patent_activity, industry, strategic_profile)
> 
> cat("üéØ TARGET COMPANIES FOR PATENTSVIEW API:\n")
üéØ TARGET COMPANIES FOR PATENTSVIEW API:
> cat(sprintf("   %d companies identified for API queries\n", nrow(patentsview_targets)))
   12 companies identified for API queries
> cat("\n   These companies have HIGH AI scores but NO patent data in Bloomberg.\n")

   These companies have HIGH AI scores but NO patent data in Bloomberg.
> cat("   Query PatentsView to validate and enrich.\n\n")
   Query PatentsView to validate and enrich.

> 
> if (nrow(patentsview_targets) > 0) {
+   print(head(patentsview_targets, 20))
+   
+   # Save targets list
+   write.csv(patentsview_targets,
+             file.path(run_dir, paste0(run_timestamp, "_13_patentsview_targets.csv")),
+             row.names = FALSE)
+   cat("\n‚úÖ Targets saved to run directory\n")
+ }
      ticker ai_score innovation_score patent_activity                       industry  strategic_profile
1    MSFT US   1.0850            0.775               0            Software & Services         AI Pioneer
2    MSFT US   1.0150            0.725               0            Software & Services Balanced Performer
3      MU US   0.9750            0.650               0 Semiconductors & Semiconductor Balanced Performer
4  005930 KS   0.9300            0.775               0 Technology Hardware & Equipmen         AI Pioneer
5    PCOR US   0.8750            0.625               0            Software & Services Balanced Performer
6  005930 KS   0.8400            0.700               0 Technology Hardware & Equipmen Balanced Performer
7    SPOT US   0.8125            0.625               0          Media & Entertainment Balanced Performer
8     SAP GR   0.7700            0.550               0            Software & Services     Underperformer
9     HDB US   0.7000            0.700               0                          Banks Balanced Performer
10    HDB US   0.7000            0.700               0                          Banks Balanced Performer
11   TSLA US   0.6875            0.625               0       Automobiles & Components Balanced Performer
12   TSLA US   0.6875            0.625               0       Automobiles & Components Balanced Performer

‚úÖ Targets saved to run directory
> 
> cat("\n")

> cat(paste(rep("=", 80), collapse = ""), "\n")
================================================================================ 
> cat("üèÅ PIPELINE EXECUTION COMPLETE\n")
üèÅ PIPELINE EXECUTION COMPLETE
> cat(paste(rep("=", 80), collapse = ""), "\n")
================================================================================ 
> 
